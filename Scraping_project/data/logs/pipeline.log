2025-09-26 11:36:45 [src.orchestrator.main:155] INFO: Starting pipeline orchestrator
2025-09-26 11:36:45 [src.orchestrator.main:156] INFO: Environment: development
2025-09-26 11:36:45 [src.orchestrator.main:157] INFO: Stage(s): all
2025-09-26 11:36:47 [src.orchestrator.main:34] INFO: ============================================================
2025-09-26 11:36:47 [src.orchestrator.main:35] INFO: STAGE 1: DISCOVERY
2025-09-26 11:36:47 [src.orchestrator.main:36] INFO: ============================================================
2025-09-26 11:36:47 [scrapy.utils.log:173] INFO: Scrapy 2.13.3 started (bot: scrapybot)
2025-09-26 11:36:47 [scrapy.utils.log:181] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.14.6',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.9.6 (default, Aug  8 2025, 19:06:38) - [Clang 17.0.0 '
           '(clang-1700.3.19.1)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.3 16 Sep 2025)',
 'cryptography': '46.0.1',
 'Platform': 'macOS-26.0-arm64-arm-64bit'}
2025-09-26 11:36:47 [discovery:44] INFO: Discovery spider initialized with max_depth=3
2025-09-26 11:36:47 [scrapy.addons:49] INFO: Enabled addons:
[]
2025-09-26 11:36:47 [scrapy.extensions.telnet:57] INFO: Telnet Password: 9fccea6cbdcb5d68
2025-09-26 11:36:47 [scrapy.middleware:101] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-09-26 11:36:47 [scrapy.crawler:135] INFO: Overridden settings:
{'CONCURRENT_REQUESTS': 32,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 16,
 'CONCURRENT_REQUESTS_PER_IP': 16,
 'DNS_TIMEOUT': 5,
 'DOWNLOAD_DELAY': 0.1,
 'DOWNLOAD_TIMEOUT': 10,
 'LOG_LEVEL': 'INFO',
 'USER_AGENT': 'UConn-Discovery-Crawler/1.0 (development)'}
2025-09-26 11:36:47 [py.warnings:109] WARNING: /Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020
  warnings.warn(

2025-09-26 11:36:48 [scrapy.middleware:101] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-09-26 11:36:48 [scrapy.middleware:101] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-09-26 11:36:49 [scrapy.middleware:101] INFO: Enabled item pipelines:
['stage1.discovery_pipeline.Stage1Pipeline']
2025-09-26 11:36:49 [scrapy.core.engine:438] INFO: Spider opened
2025-09-26 11:36:49 [twisted:147] CRITICAL: While calling system event trigger handler
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/base.py", line 518, in _continueFiring
    callable(*args, **kwargs)
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/base.py", line 951, in _reallyStartRunning
    self._signals.install()
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/_signals.py", line 190, in install
    d.install()
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/_signals.py", line 149, in install
    signal.signal(signal.SIGINT, self._sigInt)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/signal.py", line 47, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
ValueError: signal only works in main thread of the main interpreter
2025-09-26 11:36:49 [twisted:147] CRITICAL: While calling system event trigger handler
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/base.py", line 518, in _continueFiring
    callable(*args, **kwargs)
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/utils/ossignal.py", line 29, in install_shutdown_handlers
    signal.signal(signal.SIGTERM, function)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/signal.py", line 47, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
ValueError: signal only works in main thread of the main interpreter
2025-09-26 11:36:49 [py.warnings:109] WARNING: /Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py:433: ScrapyDeprecationWarning: stage1.discovery_spider.DiscoverySpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2025-09-26 11:36:49 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 11:36:49 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 11:36:49 [scrapy.extensions.logstats:65] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-09-26 11:36:49 [src.orchestrator.main:189] ERROR: Pipeline failed: This event loop is already running
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 174, in main
    await run_stage1_discovery(config)
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 60, in run_stage1_discovery
    await asyncio.get_event_loop().run_in_executor(None, process.start)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 502, in start
    reactor.run(installSignalHandlers=install_signal_handlers)  # blocking call
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/asyncioreactor.py", line 253, in run
    self._asyncioEventloop.run_forever()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 586, in run_forever
    self._check_running()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 578, in _check_running
    raise RuntimeError('This event loop is already running')
RuntimeError: This event loop is already running
2025-09-26 11:36:49 [scrapy.extensions.telnet:69] INFO: Telnet console listening on 127.0.0.1:6023
2025-09-26 11:36:49 [discovery:54] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 11:36:49 [twisted:147] CRITICAL: Unhandled error in Deferred:
2025-09-26 11:36:49 [twisted:147] CRITICAL: 
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/core/engine.py", line 145, in start
    await maybe_deferred_to_future(self._closewait)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1853, in _inlineCallbacks
    result = context.run(
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/python/failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 158, in crawl
    yield self.engine.start()
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1257, in adapt
    extracted: _SelfResultT | Failure = result.result()
asyncio.exceptions.CancelledError
2025-09-26 11:37:11 [src.orchestrator.main:155] INFO: Starting pipeline orchestrator
2025-09-26 11:37:11 [src.orchestrator.main:156] INFO: Environment: development
2025-09-26 11:37:11 [src.orchestrator.main:157] INFO: Stage(s): all
2025-09-26 11:37:11 [src.orchestrator.main:34] INFO: ============================================================
2025-09-26 11:37:11 [src.orchestrator.main:35] INFO: STAGE 1: DISCOVERY
2025-09-26 11:37:11 [src.orchestrator.main:36] INFO: ============================================================
2025-09-26 11:37:11 [scrapy.utils.log:173] INFO: Scrapy 2.13.3 started (bot: scrapybot)
2025-09-26 11:37:11 [scrapy.utils.log:181] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.14.6',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.9.6 (default, Aug  8 2025, 19:06:38) - [Clang 17.0.0 '
           '(clang-1700.3.19.1)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.3 16 Sep 2025)',
 'cryptography': '46.0.1',
 'Platform': 'macOS-26.0-arm64-arm-64bit'}
2025-09-26 11:37:11 [discovery:44] INFO: Discovery spider initialized with max_depth=3
2025-09-26 11:37:11 [scrapy.addons:49] INFO: Enabled addons:
[]
2025-09-26 11:37:11 [scrapy.extensions.telnet:57] INFO: Telnet Password: 5700895aa5a77068
2025-09-26 11:37:11 [scrapy.middleware:101] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-09-26 11:37:11 [scrapy.crawler:135] INFO: Overridden settings:
{'CONCURRENT_REQUESTS': 32,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 16,
 'CONCURRENT_REQUESTS_PER_IP': 16,
 'DNS_TIMEOUT': 5,
 'DOWNLOAD_DELAY': 0.1,
 'DOWNLOAD_TIMEOUT': 10,
 'LOG_LEVEL': 'INFO',
 'USER_AGENT': 'UConn-Discovery-Crawler/1.0 (development)'}
2025-09-26 11:37:11 [py.warnings:109] WARNING: /Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020
  warnings.warn(

2025-09-26 11:37:11 [scrapy.middleware:101] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-09-26 11:37:11 [scrapy.middleware:101] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-09-26 11:37:11 [scrapy.middleware:101] INFO: Enabled item pipelines:
['stage1.discovery_pipeline.Stage1Pipeline']
2025-09-26 11:37:11 [scrapy.core.engine:438] INFO: Spider opened
2025-09-26 11:37:11 [twisted:147] CRITICAL: While calling system event trigger handler
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/base.py", line 518, in _continueFiring
    callable(*args, **kwargs)
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/base.py", line 951, in _reallyStartRunning
    self._signals.install()
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/_signals.py", line 190, in install
    d.install()
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/_signals.py", line 149, in install
    signal.signal(signal.SIGINT, self._sigInt)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/signal.py", line 47, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
ValueError: signal only works in main thread of the main interpreter
2025-09-26 11:37:11 [twisted:147] CRITICAL: While calling system event trigger handler
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/base.py", line 518, in _continueFiring
    callable(*args, **kwargs)
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/utils/ossignal.py", line 29, in install_shutdown_handlers
    signal.signal(signal.SIGTERM, function)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/signal.py", line 47, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
ValueError: signal only works in main thread of the main interpreter
2025-09-26 11:37:11 [py.warnings:109] WARNING: /Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py:433: ScrapyDeprecationWarning: stage1.discovery_spider.DiscoverySpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2025-09-26 11:37:11 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 11:37:11 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 11:37:11 [scrapy.extensions.logstats:65] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-09-26 11:37:11 [src.orchestrator.main:189] ERROR: Pipeline failed: This event loop is already running
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 174, in main
    await run_stage1_discovery(config)
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 60, in run_stage1_discovery
    await asyncio.get_event_loop().run_in_executor(None, process.start)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 502, in start
    reactor.run(installSignalHandlers=install_signal_handlers)  # blocking call
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/asyncioreactor.py", line 253, in run
    self._asyncioEventloop.run_forever()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 586, in run_forever
    self._check_running()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 578, in _check_running
    raise RuntimeError('This event loop is already running')
RuntimeError: This event loop is already running
2025-09-26 11:37:11 [scrapy.extensions.telnet:69] INFO: Telnet console listening on 127.0.0.1:6023
2025-09-26 11:37:11 [discovery:54] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 11:37:11 [twisted:147] CRITICAL: Unhandled error in Deferred:
2025-09-26 11:37:11 [twisted:147] CRITICAL: 
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/core/engine.py", line 145, in start
    await maybe_deferred_to_future(self._closewait)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1853, in _inlineCallbacks
    result = context.run(
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/python/failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 158, in crawl
    yield self.engine.start()
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1257, in adapt
    extracted: _SelfResultT | Failure = result.result()
asyncio.exceptions.CancelledError
2025-09-26 11:43:42 [src.orchestrator.main:154] INFO: Starting pipeline orchestrator
2025-09-26 11:43:42 [src.orchestrator.main:155] INFO: Environment: development
2025-09-26 11:43:42 [src.orchestrator.main:156] INFO: Stage(s): all
2025-09-26 11:43:42 [src.orchestrator.main:34] INFO: ============================================================
2025-09-26 11:43:42 [src.orchestrator.main:35] INFO: STAGE 1: DISCOVERY
2025-09-26 11:43:42 [src.orchestrator.main:36] INFO: ============================================================
2025-09-26 11:43:42 [scrapy.utils.log:173] INFO: Scrapy 2.13.3 started (bot: scrapybot)
2025-09-26 11:43:42 [scrapy.utils.log:181] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.14.6',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.9.6 (default, Aug  8 2025, 19:06:38) - [Clang 17.0.0 '
           '(clang-1700.3.19.1)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.3 16 Sep 2025)',
 'cryptography': '46.0.1',
 'Platform': 'macOS-26.0-arm64-arm-64bit'}
2025-09-26 11:43:42 [discovery:44] INFO: Discovery spider initialized with max_depth=3
2025-09-26 11:43:42 [scrapy.addons:49] INFO: Enabled addons:
[]
2025-09-26 11:43:42 [scrapy.extensions.telnet:57] INFO: Telnet Password: af856232fe3cae14
2025-09-26 11:43:42 [scrapy.middleware:101] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-09-26 11:43:42 [scrapy.crawler:135] INFO: Overridden settings:
{'CONCURRENT_REQUESTS': 32,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 16,
 'CONCURRENT_REQUESTS_PER_IP': 16,
 'DNS_TIMEOUT': 5,
 'DOWNLOAD_DELAY': 0.1,
 'DOWNLOAD_TIMEOUT': 10,
 'LOG_LEVEL': 'INFO',
 'USER_AGENT': 'UConn-Discovery-Crawler/1.0 (development)'}
2025-09-26 11:43:42 [py.warnings:109] WARNING: /Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020
  warnings.warn(

2025-09-26 11:43:42 [scrapy.middleware:101] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-09-26 11:43:42 [scrapy.middleware:101] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-09-26 11:43:42 [scrapy.middleware:101] INFO: Enabled item pipelines:
['stage1.discovery_pipeline.Stage1Pipeline']
2025-09-26 11:43:42 [src.orchestrator.main:188] ERROR: Pipeline failed: This event loop is already running
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 173, in main
    await run_stage1_discovery(config)
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 59, in run_stage1_discovery
    process.start(stop_after_crawl=False, install_signal_handlers=False)
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 502, in start
    reactor.run(installSignalHandlers=install_signal_handlers)  # blocking call
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/asyncioreactor.py", line 253, in run
    self._asyncioEventloop.run_forever()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 586, in run_forever
    self._check_running()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 578, in _check_running
    raise RuntimeError('This event loop is already running')
RuntimeError: This event loop is already running
2025-09-26 11:43:42 [scrapy.core.engine:438] INFO: Spider opened
2025-09-26 11:43:42 [py.warnings:109] WARNING: /Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py:433: ScrapyDeprecationWarning: stage1.discovery_spider.DiscoverySpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2025-09-26 11:43:42 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 11:43:42 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 11:43:42 [scrapy.extensions.logstats:65] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-09-26 11:43:42 [scrapy.extensions.telnet:69] INFO: Telnet console listening on 127.0.0.1:6023
2025-09-26 11:43:42 [discovery:54] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 11:43:43 [twisted:147] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/_threads/_team.py", line 192, in doWork
    task()
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/python/threadpool.py", line 277, in inContext
    inContext.onResult(ok, result)  # type: ignore[attr-defined]
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/threads.py", line 59, in onResult
    reactor.callFromThread(d.callback, result)
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/asyncioreactor.py", line 294, in callFromThread
    self._asyncioEventloop.call_soon_threadsafe(g)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 791, in call_soon_threadsafe
    self._check_closed()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 510, in _check_closed
    raise RuntimeError('Event loop is closed')
builtins.RuntimeError: Event loop is closed

2025-09-26 12:20:00 [src.orchestrator.main:157] INFO: Starting pipeline orchestrator
2025-09-26 12:20:00 [src.orchestrator.main:158] INFO: Environment: development
2025-09-26 12:20:00 [src.orchestrator.main:159] INFO: Stage(s): all
2025-09-26 12:20:00 [src.orchestrator.main:37] INFO: ============================================================
2025-09-26 12:20:00 [src.orchestrator.main:38] INFO: STAGE 1: DISCOVERY
2025-09-26 12:20:00 [src.orchestrator.main:39] INFO: ============================================================
2025-09-26 12:20:00 [scrapy.utils.log:173] INFO: Scrapy 2.13.3 started (bot: scrapybot)
2025-09-26 12:20:00 [scrapy.utils.log:181] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.14.6',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.9.6 (default, Aug  8 2025, 19:06:38) - [Clang 17.0.0 '
           '(clang-1700.3.19.1)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.3 16 Sep 2025)',
 'cryptography': '46.0.1',
 'Platform': 'macOS-26.0-arm64-arm-64bit'}
2025-09-26 12:20:00 [discovery:44] INFO: Discovery spider initialized with max_depth=3
2025-09-26 12:20:00 [scrapy.addons:49] INFO: Enabled addons:
[]
2025-09-26 12:20:00 [scrapy.extensions.telnet:57] INFO: Telnet Password: 6b74d20281b6a90e
2025-09-26 12:20:00 [scrapy.middleware:101] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-09-26 12:20:00 [scrapy.crawler:135] INFO: Overridden settings:
{'CONCURRENT_REQUESTS': 32,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 16,
 'CONCURRENT_REQUESTS_PER_IP': 16,
 'DNS_TIMEOUT': 5,
 'DOWNLOAD_DELAY': 0.1,
 'DOWNLOAD_TIMEOUT': 10,
 'LOG_LEVEL': 'INFO',
 'USER_AGENT': 'UConn-Discovery-Crawler/1.0 (development)'}
2025-09-26 12:20:00 [py.warnings:109] WARNING: /Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020
  warnings.warn(

2025-09-26 12:20:00 [scrapy.middleware:101] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-09-26 12:20:00 [scrapy.middleware:101] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-09-26 12:20:00 [scrapy.middleware:101] INFO: Enabled item pipelines:
['stage1.discovery_pipeline.Stage1Pipeline']
2025-09-26 12:20:00 [src.orchestrator.main:191] ERROR: Pipeline failed: This event loop is already running
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 176, in main
    await run_stage1_discovery(config)
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 62, in run_stage1_discovery
    process.start(stop_after_crawl=False, install_signal_handlers=False)
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 502, in start
    reactor.run(installSignalHandlers=install_signal_handlers)  # blocking call
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/asyncioreactor.py", line 253, in run
    self._asyncioEventloop.run_forever()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 586, in run_forever
    self._check_running()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 578, in _check_running
    raise RuntimeError('This event loop is already running')
RuntimeError: This event loop is already running
2025-09-26 12:20:00 [scrapy.core.engine:438] INFO: Spider opened
2025-09-26 12:20:00 [py.warnings:109] WARNING: /Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py:433: ScrapyDeprecationWarning: stage1.discovery_spider.DiscoverySpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2025-09-26 12:20:00 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 12:20:00 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 12:20:00 [scrapy.extensions.logstats:65] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-09-26 12:20:00 [scrapy.extensions.telnet:69] INFO: Telnet console listening on 127.0.0.1:6023
2025-09-26 12:20:00 [discovery:54] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 12:20:00 [twisted:147] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/_threads/_team.py", line 192, in doWork
    task()
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/python/threadpool.py", line 277, in inContext
    inContext.onResult(ok, result)  # type: ignore[attr-defined]
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/threads.py", line 59, in onResult
    reactor.callFromThread(d.callback, result)
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/asyncioreactor.py", line 294, in callFromThread
    self._asyncioEventloop.call_soon_threadsafe(g)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 791, in call_soon_threadsafe
    self._check_closed()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 510, in _check_closed
    raise RuntimeError('Event loop is closed')
builtins.RuntimeError: Event loop is closed

2025-09-26 12:27:00 [src.orchestrator.main:164] INFO: Starting pipeline orchestrator
2025-09-26 12:27:00 [src.orchestrator.main:165] INFO: Environment: development
2025-09-26 12:27:00 [src.orchestrator.main:166] INFO: Stage(s): all
2025-09-26 12:27:00 [src.orchestrator.main:38] INFO: ============================================================
2025-09-26 12:27:00 [src.orchestrator.main:39] INFO: STAGE 1: DISCOVERY
2025-09-26 12:27:00 [src.orchestrator.main:40] INFO: ============================================================
2025-09-26 12:27:00 [scrapy.utils.log:173] INFO: Scrapy 2.13.3 started (bot: scrapybot)
2025-09-26 12:27:00 [scrapy.utils.log:181] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.14.6',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.9.6 (default, Aug  8 2025, 19:06:38) - [Clang 17.0.0 '
           '(clang-1700.3.19.1)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.3 16 Sep 2025)',
 'cryptography': '46.0.1',
 'Platform': 'macOS-26.0-arm64-arm-64bit'}
2025-09-26 12:27:00 [discovery:44] INFO: Discovery spider initialized with max_depth=3
2025-09-26 12:27:00 [scrapy.addons:49] INFO: Enabled addons:
[]
2025-09-26 12:27:00 [scrapy.extensions.telnet:57] INFO: Telnet Password: 97094d8217c47a84
2025-09-26 12:27:00 [scrapy.middleware:101] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-09-26 12:27:00 [scrapy.crawler:135] INFO: Overridden settings:
{'CONCURRENT_REQUESTS': 32,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 16,
 'CONCURRENT_REQUESTS_PER_IP': 16,
 'DNS_TIMEOUT': 5,
 'DOWNLOAD_DELAY': 0.1,
 'DOWNLOAD_TIMEOUT': 10,
 'LOG_LEVEL': 'INFO',
 'USER_AGENT': 'UConn-Discovery-Crawler/1.0 (development)'}
2025-09-26 12:27:00 [py.warnings:109] WARNING: /Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020
  warnings.warn(

2025-09-26 12:27:00 [scrapy.middleware:101] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-09-26 12:27:00 [scrapy.middleware:101] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-09-26 12:27:01 [scrapy.middleware:101] INFO: Enabled item pipelines:
['stage1.discovery_pipeline.Stage1Pipeline']
2025-09-26 12:27:01 [scrapy.core.engine:438] INFO: Spider opened
2025-09-26 12:27:01 [py.warnings:109] WARNING: /Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py:433: ScrapyDeprecationWarning: stage1.discovery_spider.DiscoverySpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2025-09-26 12:27:01 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 12:27:01 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 12:27:01 [scrapy.extensions.logstats:65] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-09-26 12:27:01 [src.orchestrator.main:198] ERROR: Pipeline failed: This event loop is already running
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 183, in main
    await run_stage1_discovery(config)
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 69, in run_stage1_discovery
    await loop.run_in_executor(None, start_crawler)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 502, in start
    reactor.run(installSignalHandlers=install_signal_handlers)  # blocking call
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/asyncioreactor.py", line 253, in run
    self._asyncioEventloop.run_forever()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 586, in run_forever
    self._check_running()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 578, in _check_running
    raise RuntimeError('This event loop is already running')
RuntimeError: This event loop is already running
2025-09-26 12:27:01 [scrapy.extensions.telnet:69] INFO: Telnet console listening on 127.0.0.1:6023
2025-09-26 12:27:01 [twisted:147] CRITICAL: Unhandled error in Deferred:
2025-09-26 12:27:01 [twisted:147] CRITICAL: 
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/core/engine.py", line 145, in start
    await maybe_deferred_to_future(self._closewait)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1853, in _inlineCallbacks
    result = context.run(
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/python/failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 158, in crawl
    yield self.engine.start()
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1257, in adapt
    extracted: _SelfResultT | Failure = result.result()
asyncio.exceptions.CancelledError
2025-09-26 12:31:13 [src.orchestrator.main:164] INFO: Starting pipeline orchestrator
2025-09-26 12:31:13 [src.orchestrator.main:165] INFO: Environment: development
2025-09-26 12:31:13 [src.orchestrator.main:166] INFO: Stage(s): all
2025-09-26 12:31:15 [src.orchestrator.main:38] INFO: ============================================================
2025-09-26 12:31:15 [src.orchestrator.main:39] INFO: STAGE 1: DISCOVERY
2025-09-26 12:31:15 [src.orchestrator.main:40] INFO: ============================================================
2025-09-26 12:31:15 [scrapy.utils.log:173] INFO: Scrapy 2.13.3 started (bot: scrapybot)
2025-09-26 12:31:15 [scrapy.utils.log:181] INFO: Versions:
{'lxml': '6.0.2',
 'libxml2': '2.14.6',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.9.6 (default, Aug  8 2025, 19:06:38) - [Clang 17.0.0 '
           '(clang-1700.3.19.1)]',
 'pyOpenSSL': '25.3.0 (OpenSSL 3.5.3 16 Sep 2025)',
 'cryptography': '46.0.1',
 'Platform': 'macOS-26.0-arm64-arm-64bit'}
2025-09-26 12:31:15 [discovery:44] INFO: Discovery spider initialized with max_depth=3
2025-09-26 12:31:15 [scrapy.addons:49] INFO: Enabled addons:
[]
2025-09-26 12:31:15 [scrapy.extensions.telnet:57] INFO: Telnet Password: 61145fbbcb44c99d
2025-09-26 12:31:15 [scrapy.middleware:101] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2025-09-26 12:31:15 [scrapy.crawler:135] INFO: Overridden settings:
{'CONCURRENT_REQUESTS': 32,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 16,
 'CONCURRENT_REQUESTS_PER_IP': 16,
 'DNS_TIMEOUT': 5,
 'DOWNLOAD_DELAY': 0.1,
 'DOWNLOAD_TIMEOUT': 10,
 'LOG_LEVEL': 'INFO',
 'USER_AGENT': 'UConn-Discovery-Crawler/1.0 (development)'}
2025-09-26 12:31:15 [py.warnings:109] WARNING: /Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020
  warnings.warn(

2025-09-26 12:31:15 [scrapy.middleware:101] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-09-26 12:31:15 [scrapy.middleware:101] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-09-26 12:31:15 [scrapy.middleware:101] INFO: Enabled item pipelines:
['stage1.discovery_pipeline.Stage1Pipeline']
2025-09-26 12:31:15 [scrapy.core.engine:438] INFO: Spider opened
2025-09-26 12:31:15 [py.warnings:109] WARNING: /Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/core/spidermw.py:433: ScrapyDeprecationWarning: stage1.discovery_spider.DiscoverySpider defines the deprecated start_requests() method. start_requests() has been deprecated in favor of a new method, start(), to support asynchronous code execution. start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace start_requests() with start(); note that start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when overriding start_requests() in a spider class, override start() as well; you can use super() to reuse the inherited start() implementation without copy-pasting. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2025-09-26 12:31:15 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 12:31:15 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 12:31:15 [scrapy.extensions.logstats:65] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-09-26 12:31:15 [src.orchestrator.main:198] ERROR: Pipeline failed: This event loop is already running
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 183, in main
    await run_stage1_discovery(config)
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 69, in run_stage1_discovery
    await loop.run_in_executor(None, start_crawler)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 502, in start
    reactor.run(installSignalHandlers=install_signal_handlers)  # blocking call
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/asyncioreactor.py", line 253, in run
    self._asyncioEventloop.run_forever()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 586, in run_forever
    self._check_running()
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py", line 578, in _check_running
    raise RuntimeError('This event loop is already running')
RuntimeError: This event loop is already running
2025-09-26 12:31:15 [scrapy.extensions.telnet:69] INFO: Telnet console listening on 127.0.0.1:6023
2025-09-26 12:31:15 [twisted:147] CRITICAL: Unhandled error in Deferred:
2025-09-26 12:31:15 [twisted:147] CRITICAL: 
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/core/engine.py", line 145, in start
    await maybe_deferred_to_future(self._closewait)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1853, in _inlineCallbacks
    result = context.run(
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/python/failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/scrapy/crawler.py", line 158, in crawl
    yield self.engine.start()
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1257, in adapt
    extracted: _SelfResultT | Failure = result.result()
asyncio.exceptions.CancelledError
2025-09-26 12:32:53 [src.orchestrator.main:170] INFO: Starting pipeline orchestrator
2025-09-26 12:32:53 [src.orchestrator.main:171] INFO: Environment: development
2025-09-26 12:32:53 [src.orchestrator.main:172] INFO: Stage(s): all
2025-09-26 12:32:54 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 12:32:54 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 12:32:54 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 12:32:54 [discovery:44] INFO: Discovery spider initialized with max_depth=3
2025-09-26 12:32:54 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 12:32:54 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 12:32:54 [src.orchestrator.main:204] ERROR: Pipeline failed: Task got bad yield: <Deferred at 0x10982e640>
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 189, in main
    await run_stage1_discovery(config)
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 71, in run_stage1_discovery
    await runner.crawl(
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1187, in __iter__
    yield self
RuntimeError: Task got bad yield: <Deferred at 0x10982e640>
2025-09-26 12:34:00 [src.orchestrator.main:170] INFO: Starting pipeline orchestrator
2025-09-26 12:34:00 [src.orchestrator.main:171] INFO: Environment: development
2025-09-26 12:34:00 [src.orchestrator.main:172] INFO: Stage(s): all
2025-09-26 12:34:00 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 12:34:00 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 12:34:00 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 12:34:00 [discovery:44] INFO: Discovery spider initialized with max_depth=3
2025-09-26 12:34:00 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 12:34:00 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 12:34:00 [src.orchestrator.main:204] ERROR: Pipeline failed: Task got bad yield: <Deferred at 0x10b1ad4f0>
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 189, in main
    await run_stage1_discovery(config)
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 71, in run_stage1_discovery
    await runner.crawl(
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1187, in __iter__
    yield self
RuntimeError: Task got bad yield: <Deferred at 0x10b1ad4f0>
2025-09-26 12:34:47 [src.orchestrator.main:170] INFO: Starting pipeline orchestrator
2025-09-26 12:34:47 [src.orchestrator.main:171] INFO: Environment: development
2025-09-26 12:34:47 [src.orchestrator.main:172] INFO: Stage(s): all
2025-09-26 12:34:47 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 12:34:47 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 12:34:47 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 12:34:47 [discovery:44] INFO: Discovery spider initialized with max_depth=3
2025-09-26 12:34:47 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 12:34:47 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 12:34:47 [src.orchestrator.main:204] ERROR: Pipeline failed: Task got bad yield: <Deferred at 0x108cd25e0>
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 189, in main
    await run_stage1_discovery(config)
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 75, in run_stage1_discovery
    await deferred
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1187, in __iter__
    yield self
RuntimeError: Task got bad yield: <Deferred at 0x108cd25e0>
2025-09-26 12:34:54 [src.orchestrator.main:170] INFO: Starting pipeline orchestrator
2025-09-26 12:34:54 [src.orchestrator.main:171] INFO: Environment: development
2025-09-26 12:34:54 [src.orchestrator.main:172] INFO: Stage(s): all
2025-09-26 12:34:54 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 12:34:54 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 12:34:54 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 12:34:54 [discovery:44] INFO: Discovery spider initialized with max_depth=3
2025-09-26 12:34:54 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 12:34:54 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 12:34:54 [src.orchestrator.main:204] ERROR: Pipeline failed: Task got bad yield: <Deferred at 0x10b6c8550>
Traceback (most recent call last):
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 189, in main
    await run_stage1_discovery(config)
  File "/Users/benjaminrussell/Desktop/Github/Scraping_project/src/orchestrator/main.py", line 75, in run_stage1_discovery
    await deferred
  File "/Users/benjaminrussell/Desktop/Github/.venv/lib/python3.9/site-packages/twisted/internet/defer.py", line 1187, in __iter__
    yield self
RuntimeError: Task got bad yield: <Deferred at 0x10b6c8550>
2025-09-26 12:36:53 [src.orchestrator.main:172] INFO: Starting pipeline orchestrator
2025-09-26 12:36:53 [src.orchestrator.main:173] INFO: Environment: development
2025-09-26 12:36:53 [src.orchestrator.main:174] INFO: Stage(s): 1
2025-09-26 12:36:54 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 12:36:54 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 12:36:54 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 12:36:54 [discovery:44] INFO: Discovery spider initialized with max_depth=3
2025-09-26 12:36:54 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 12:36:54 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 12:36:54 [scrapy.utils.signal:82] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x1066af800>>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/tcp.py", line 1334, in startListening
    skt.bind(addr)
PermissionError: [Errno 1] Operation not permitted

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/utils/defer.py", line 400, in maybeDeferred_coro
    result = f(*args, **kw)
  File "/opt/anaconda3/lib/python3.12/site-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/extensions/telnet.py", line 67, in start_listening
    self.port: Port = listen_tcp(self.portrange, self.host, self)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/utils/reactor.py", line 41, in listen_tcp
    return reactor.listenTCP(x, factory, interface=host)
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/posixbase.py", line 364, in listenTCP
    p.startListening()
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/tcp.py", line 1336, in startListening
    raise CannotListenError(self.interface, self.port, le)
twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [Errno 1] Operation not permitted.
2025-09-26 12:36:54 [discovery:54] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 12:37:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://privacy.uconn.edu/privacy-notices/website> (failed 3 times): User timeout caused connection failure: Getting https://privacy.uconn.edu/privacy-notices/website took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/> (failed 3 times): User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/ took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://admissions.uconn.edu/apply/> (failed 3 times): User timeout caused connection failure: Getting https://admissions.uconn.edu/apply/ took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/twice-as-nice/> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/twice-as-nice/ took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://grad.uconn.edu/prospective-student/> (failed 3 times): User timeout caused connection failure: Getting https://grad.uconn.edu/prospective-student/ took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://www.foundation.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://www.foundation.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://privacy.uconn.edu/privacy-notices/website>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://privacy.uconn.edu/privacy-notices/website took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/ took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://admissions.uconn.edu/apply/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://admissions.uconn.edu/apply/ took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/twice-as-nice/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/twice-as-nice/ took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://grad.uconn.edu/prospective-student/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://grad.uconn.edu/prospective-student/ took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://www.foundation.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.foundation.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://privacy.uconn.edu/university-website-notice/> (failed 3 times): User timeout caused connection failure: Getting https://privacy.uconn.edu/university-website-notice/ took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/> (failed 3 times): User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/ took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://privacy.uconn.edu/university-website-notice/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://privacy.uconn.edu/university-website-notice/ took longer than 10.0 seconds..
2025-09-26 12:37:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/ took longer than 10.0 seconds..
2025-09-26 12:37:34 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:34 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:34 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/search> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/search took longer than 10.0 seconds..
2025-09-26 12:37:34 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/search>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/search took longer than 10.0 seconds..
2025-09-26 12:37:34 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/az> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/az took longer than 10.0 seconds..
2025-09-26 12:37:34 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/az>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/az took longer than 10.0 seconds..
2025-09-26 12:37:34 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/ took longer than 10.0 seconds..
2025-09-26 12:37:34 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/ took longer than 10.0 seconds..
2025-09-26 12:37:34 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/prospective-students/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/prospective-students/ took longer than 10.0 seconds..
2025-09-26 12:37:34 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/prospective-students/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/prospective-students/ took longer than 10.0 seconds..
2025-09-26 12:37:34 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/tuition-and-costs/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/tuition-and-costs/ took longer than 10.0 seconds..
2025-09-26 12:37:34 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/tuition-and-costs/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/tuition-and-costs/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/visit-campus/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/visit-campus/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/visit-campus/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/visit-campus/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/administration/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/administration/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/facts/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/facts/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/history/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/history/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/history/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/history/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/schools-and-colleges/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/schools-and-colleges/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/schools-and-colleges/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/schools-and-colleges/ took longer than 10.0 seconds..
2025-09-26 12:37:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/academic-resources/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/academic-resources/ took longer than 10.0 seconds..
2025-09-26 12:37:36 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/academic-resources/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/academic-resources/ took longer than 10.0 seconds..
2025-09-26 12:37:36 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/enrichment-opportunities/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/enrichment-opportunities/ took longer than 10.0 seconds..
2025-09-26 12:37:36 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/enrichment-opportunities/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/enrichment-opportunities/ took longer than 10.0 seconds..
2025-09-26 12:37:36 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/ took longer than 10.0 seconds..
2025-09-26 12:37:36 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/ took longer than 10.0 seconds..
2025-09-26 12:37:44 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/living-on-campus/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/living-on-campus/ took longer than 10.0 seconds..
2025-09-26 12:37:44 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/living-on-campus/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/living-on-campus/ took longer than 10.0 seconds..
2025-09-26 12:37:44 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/campus-health-safety/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/campus-health-safety/ took longer than 10.0 seconds..
2025-09-26 12:37:44 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/campus-health-safety/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/campus-health-safety/ took longer than 10.0 seconds..
2025-09-26 12:37:44 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/arts-culture/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/arts-culture/ took longer than 10.0 seconds..
2025-09-26 12:37:44 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/arts-culture/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/arts-culture/ took longer than 10.0 seconds..
2025-09-26 12:37:44 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/activities-recreation/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/activities-recreation/ took longer than 10.0 seconds..
2025-09-26 12:37:44 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/activities-recreation/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/activities-recreation/ took longer than 10.0 seconds..
2025-09-26 12:37:44 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/research/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/research/ took longer than 10.0 seconds..
2025-09-26 12:37:44 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/research/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/research/ took longer than 10.0 seconds..
2025-09-26 12:37:44 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/athletics/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/athletics/ took longer than 10.0 seconds..
2025-09-26 12:37:44 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/athletics/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/athletics/ took longer than 10.0 seconds..
2025-09-26 12:37:45 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/uconn-health/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/uconn-health/ took longer than 10.0 seconds..
2025-09-26 12:37:45 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/uconn-health/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/uconn-health/ took longer than 10.0 seconds..
2025-09-26 12:37:45 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/facts/campuses/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/campuses/ took longer than 10.0 seconds..
2025-09-26 12:37:45 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/facts/campuses/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/campuses/ took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://averypoint.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://averypoint.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://health.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://health.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://hartford.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://hartford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://averypoint.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://averypoint.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://health.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://health.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://hartford.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://hartford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://www.law.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://www.law.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://stamford.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://stamford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://www.law.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.law.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://stamford.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://stamford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:37:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:04 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://waterbury.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://waterbury.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:04 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://waterbury.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://waterbury.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:04 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://global.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://global.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://global.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://global.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/az-index/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/az-index/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/az-index/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/az-index/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/careers/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/careers/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/careers/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/careers/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://facultystaff.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://facultystaff.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/construction/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/construction/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://facultystaff.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://facultystaff.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/construction/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/construction/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/entrepreneurship/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/entrepreneurship/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/entrepreneurship/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/entrepreneurship/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://accessibility.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-students/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-students/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://accessibility.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.aacc.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.aacc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:05 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-students/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-students/ took longer than 10.0 seconds..
2025-09-26 12:38:06 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-alumni/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-alumni/ took longer than 10.0 seconds..
2025-09-26 12:38:06 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.aacc.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.aacc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:06 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://achieve.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://achieve.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:06 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-alumni/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-alumni/ took longer than 10.0 seconds..
2025-09-26 12:38:06 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-visitors/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-visitors/ took longer than 10.0 seconds..
2025-09-26 12:38:06 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://achieve.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://achieve.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:06 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://registrar.uconn.edu/academic-calendar/> (failed 3 times): User timeout caused connection failure: Getting http://registrar.uconn.edu/academic-calendar/ took longer than 10.0 seconds..
2025-09-26 12:38:06 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-visitors/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-visitors/ took longer than 10.0 seconds..
2025-09-26 12:38:06 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-business-partners/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-business-partners/ took longer than 10.0 seconds..
2025-09-26 12:38:06 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://registrar.uconn.edu/academic-calendar/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://registrar.uconn.edu/academic-calendar/ took longer than 10.0 seconds..
2025-09-26 12:38:06 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-business-partners/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-business-partners/ took longer than 10.0 seconds..
2025-09-26 12:38:14 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/disclaimers-privacy-copyright/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/disclaimers-privacy-copyright/ took longer than 10.0 seconds..
2025-09-26 12:38:14 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.aces.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.aces.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:14 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/disclaimers-privacy-copyright/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/disclaimers-privacy-copyright/ took longer than 10.0 seconds..
2025-09-26 12:38:14 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.aces.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.aces.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:14 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://uconn.edu/about-us/administration/> (failed 3 times): User timeout caused connection failure: Getting http://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:38:14 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://uconn.edu/about-us/administration/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:38:14 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.catalog.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.catalog.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:14 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.catalog.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.catalog.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:14 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://academicplan.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://academicplan.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:14 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://academicplan.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://academicplan.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:14 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.myagnr.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.myagnr.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:14 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.myagnr.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.myagnr.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:14 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cap.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cap.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:15 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cap.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cap.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:15 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://advising.clas.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://advising.clas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:15 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://advising.clas.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://advising.clas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:15 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://students.uconn.edu/academic-support-services/> (failed 3 times): User timeout caused connection failure: Getting http://students.uconn.edu/academic-support-services/ took longer than 10.0 seconds..
2025-09-26 12:38:15 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://students.uconn.edu/academic-support-services/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://students.uconn.edu/academic-support-services/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accessibility.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.business.uconn.edu/accounting/> (failed 3 times): User timeout caused connection failure: Getting http://www.business.uconn.edu/accounting/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accountingoffice.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accountingoffice.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accountspayable.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accountspayable.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accessibility.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.business.uconn.edu/accounting/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.business.uconn.edu/accounting/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accountingoffice.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accountingoffice.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accountspayable.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accountspayable.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.neasc.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.neasc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://grad.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://grad.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cpca.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cpca.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.neasc.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.neasc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://grad.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://grad.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cpca.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cpca.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://admissions.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://admissions.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://admissions.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://admissions.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:34 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.newhusky.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.newhusky.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:34 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.newhusky.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.newhusky.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:34 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.advance.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.advance.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.advance.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.advance.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.airforce.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.airforce.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.airforce.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.airforce.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.iaas.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.iaas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.iaas.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.iaas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.are.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.are.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://health.uconn.edu/aging> (failed 3 times): User timeout caused connection failure: Getting http://health.uconn.edu/aging took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.are.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.are.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://health.uconn.edu/aging>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://health.uconn.edu/aging took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://rhsa.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://rhsa.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://rhsa.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://rhsa.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cag.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cag.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://aod.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://aod.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cag.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cag.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://alert.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://alert.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:35 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://aod.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://aod.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:36 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.alliedhealth.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.alliedhealth.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:36 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://alert.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://alert.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:36 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://alumnimagazine.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://alumnimagazine.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:36 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.alliedhealth.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.alliedhealth.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:36 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.ucaeli.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:36 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://alumnimagazine.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://alumnimagazine.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:36 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://ucaeli.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:36 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.ucaeli.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:36 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://asl.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://asl.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:36 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://ucaeli.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:36 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://asl.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://asl.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:44 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://americanstudies.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://americanstudies.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:44 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://ovpr.uconn.edu/services/rics/animal/animal-care/> (failed 3 times): User timeout caused connection failure: Getting https://ovpr.uconn.edu/services/rics/animal/animal-care/ took longer than 10.0 seconds..
2025-09-26 12:38:44 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://americanstudies.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://americanstudies.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:44 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://ovpr.uconn.edu/services/rics/animal/animal-care/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ovpr.uconn.edu/services/rics/animal/animal-care/ took longer than 10.0 seconds..
2025-09-26 12:38:44 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.animalscience.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.animalscience.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:44 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.animalscience.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.animalscience.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:44 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://anthropology.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://anthropology.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:44 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://anthropology.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://anthropology.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:44 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://cgi.uconn.edu/cagt-dedication/> (failed 3 times): User timeout caused connection failure: Getting http://cgi.uconn.edu/cagt-dedication/ took longer than 10.0 seconds..
2025-09-26 12:38:44 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://cgi.uconn.edu/cagt-dedication/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://cgi.uconn.edu/cagt-dedication/ took longer than 10.0 seconds..
2025-09-26 12:38:44 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.appliedresearch.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.appliedresearch.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:44 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.appliedresearch.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.appliedresearch.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:44 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.uconnarboretum.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.uconnarboretum.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:45 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.uconnarboretum.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.uconnarboretum.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:45 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cac.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cac.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:45 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cac.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cac.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:38:45 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://lib.uconn.edu/location/asc/> (failed 3 times): User timeout caused connection failure: Getting https://lib.uconn.edu/location/asc/ took longer than 10.0 seconds..
2025-09-26 12:38:45 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://lib.uconn.edu/location/asc/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://lib.uconn.edu/location/asc/ took longer than 10.0 seconds..
2025-09-26 12:41:51 [src.orchestrator.main:172] INFO: Starting pipeline orchestrator
2025-09-26 12:41:51 [src.orchestrator.main:173] INFO: Environment: development
2025-09-26 12:41:51 [src.orchestrator.main:174] INFO: Stage(s): 1
2025-09-26 12:41:52 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 12:41:52 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 12:41:52 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 12:41:52 [discovery:44] INFO: Discovery spider initialized with max_depth=3
2025-09-26 12:41:52 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 12:41:52 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 12:41:52 [discovery:54] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 12:41:56 [discovery:78] ERROR: Error processing seed URL at line 53346: http://C:\Users\rei12001\AppData\Local\Microsoft\Windows\INetCache\Content.OutlookTZE6E5P\president.uconn.edu - Port could not be cast to integer value as '\\Users\\rei12001\\AppData\\Local\\Microsoft\\Windows\\INetCache\\Content.OutlookTZE6E5P\\president.uconn.edu'
2025-09-26 12:42:03 [discovery:81] INFO: Loaded 142004 unique seed URLs (know when seeds go stale)
2025-09-26 12:42:54 [src.orchestrator.main:172] INFO: Starting pipeline orchestrator
2025-09-26 12:42:54 [src.orchestrator.main:173] INFO: Environment: development
2025-09-26 12:42:54 [src.orchestrator.main:174] INFO: Stage(s): all
2025-09-26 12:42:54 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 12:42:54 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 12:42:54 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 12:42:54 [discovery:44] INFO: Discovery spider initialized with max_depth=3
2025-09-26 12:42:54 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 12:42:54 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 12:42:54 [discovery:54] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 12:42:58 [discovery:78] ERROR: Error processing seed URL at line 53346: http://C:\Users\rei12001\AppData\Local\Microsoft\Windows\INetCache\Content.OutlookTZE6E5P\president.uconn.edu - Port could not be cast to integer value as '\\Users\\rei12001\\AppData\\Local\\Microsoft\\Windows\\INetCache\\Content.OutlookTZE6E5P\\president.uconn.edu'
2025-09-26 12:43:05 [discovery:81] INFO: Loaded 142004 unique seed URLs (know when seeds go stale)
2025-09-26 12:44:42 [src.orchestrator.main:172] INFO: Starting pipeline orchestrator
2025-09-26 12:44:42 [src.orchestrator.main:173] INFO: Environment: development
2025-09-26 12:44:42 [src.orchestrator.main:174] INFO: Stage(s): 1
2025-09-26 12:44:42 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 12:44:42 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 12:44:42 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 12:44:42 [discovery:45] INFO: Discovery spider initialized with max_depth=3
2025-09-26 12:44:42 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 12:44:42 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 12:44:42 [scrapy.utils.signal:82] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x107a45580>>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/tcp.py", line 1334, in startListening
    skt.bind(addr)
PermissionError: [Errno 1] Operation not permitted

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/utils/defer.py", line 400, in maybeDeferred_coro
    result = f(*args, **kw)
  File "/opt/anaconda3/lib/python3.12/site-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/extensions/telnet.py", line 67, in start_listening
    self.port: Port = listen_tcp(self.portrange, self.host, self)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/utils/reactor.py", line 41, in listen_tcp
    return reactor.listenTCP(x, factory, interface=host)
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/posixbase.py", line 364, in listenTCP
    p.startListening()
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/tcp.py", line 1336, in startListening
    raise CannotListenError(self.interface, self.port, le)
twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [Errno 1] Operation not permitted.
2025-09-26 12:44:42 [discovery:55] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 12:45:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://privacy.uconn.edu/privacy-notices/website> (failed 3 times): User timeout caused connection failure: Getting https://privacy.uconn.edu/privacy-notices/website took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://admissions.uconn.edu/apply/> (failed 3 times): User timeout caused connection failure: Getting https://admissions.uconn.edu/apply/ took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://grad.uconn.edu/prospective-student/> (failed 3 times): User timeout caused connection failure: Getting https://grad.uconn.edu/prospective-student/ took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://www.foundation.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://www.foundation.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/twice-as-nice/> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/twice-as-nice/ took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/> (failed 3 times): User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/ took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://privacy.uconn.edu/privacy-notices/website>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://privacy.uconn.edu/privacy-notices/website took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://admissions.uconn.edu/apply/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://admissions.uconn.edu/apply/ took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://grad.uconn.edu/prospective-student/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://grad.uconn.edu/prospective-student/ took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://www.foundation.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.foundation.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/twice-as-nice/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/twice-as-nice/ took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/ took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/> (failed 3 times): User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/ took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://privacy.uconn.edu/university-website-notice/> (failed 3 times): User timeout caused connection failure: Getting https://privacy.uconn.edu/university-website-notice/ took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/ took longer than 10.0 seconds..
2025-09-26 12:45:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://privacy.uconn.edu/university-website-notice/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://privacy.uconn.edu/university-website-notice/ took longer than 10.0 seconds..
2025-09-26 12:45:22 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:22 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:22 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/search> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/search took longer than 10.0 seconds..
2025-09-26 12:45:22 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/search>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/search took longer than 10.0 seconds..
2025-09-26 12:45:22 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/az> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/az took longer than 10.0 seconds..
2025-09-26 12:45:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/az>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/az took longer than 10.0 seconds..
2025-09-26 12:45:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/ took longer than 10.0 seconds..
2025-09-26 12:45:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/ took longer than 10.0 seconds..
2025-09-26 12:45:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/prospective-students/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/prospective-students/ took longer than 10.0 seconds..
2025-09-26 12:45:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/prospective-students/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/prospective-students/ took longer than 10.0 seconds..
2025-09-26 12:45:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/tuition-and-costs/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/tuition-and-costs/ took longer than 10.0 seconds..
2025-09-26 12:45:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/tuition-and-costs/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/tuition-and-costs/ took longer than 10.0 seconds..
2025-09-26 12:45:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/visit-campus/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/visit-campus/ took longer than 10.0 seconds..
2025-09-26 12:45:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/visit-campus/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/visit-campus/ took longer than 10.0 seconds..
2025-09-26 12:45:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/ took longer than 10.0 seconds..
2025-09-26 12:45:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/ took longer than 10.0 seconds..
2025-09-26 12:45:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/administration/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:45:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/administration/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:45:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/facts/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/ took longer than 10.0 seconds..
2025-09-26 12:45:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/facts/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/ took longer than 10.0 seconds..
2025-09-26 12:45:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/history/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/history/ took longer than 10.0 seconds..
2025-09-26 12:45:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/history/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/history/ took longer than 10.0 seconds..
2025-09-26 12:45:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/ took longer than 10.0 seconds..
2025-09-26 12:45:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/ took longer than 10.0 seconds..
2025-09-26 12:45:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/schools-and-colleges/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/schools-and-colleges/ took longer than 10.0 seconds..
2025-09-26 12:45:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/academic-resources/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/academic-resources/ took longer than 10.0 seconds..
2025-09-26 12:45:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/schools-and-colleges/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/schools-and-colleges/ took longer than 10.0 seconds..
2025-09-26 12:45:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/academic-resources/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/academic-resources/ took longer than 10.0 seconds..
2025-09-26 12:45:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/enrichment-opportunities/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/enrichment-opportunities/ took longer than 10.0 seconds..
2025-09-26 12:45:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/enrichment-opportunities/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/enrichment-opportunities/ took longer than 10.0 seconds..
2025-09-26 12:45:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/ took longer than 10.0 seconds..
2025-09-26 12:45:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/ took longer than 10.0 seconds..
2025-09-26 12:45:32 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/living-on-campus/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/living-on-campus/ took longer than 10.0 seconds..
2025-09-26 12:45:32 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/living-on-campus/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/living-on-campus/ took longer than 10.0 seconds..
2025-09-26 12:45:32 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/campus-health-safety/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/campus-health-safety/ took longer than 10.0 seconds..
2025-09-26 12:45:32 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/campus-health-safety/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/campus-health-safety/ took longer than 10.0 seconds..
2025-09-26 12:45:32 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/arts-culture/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/arts-culture/ took longer than 10.0 seconds..
2025-09-26 12:45:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/arts-culture/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/arts-culture/ took longer than 10.0 seconds..
2025-09-26 12:45:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/activities-recreation/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/activities-recreation/ took longer than 10.0 seconds..
2025-09-26 12:45:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/activities-recreation/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/activities-recreation/ took longer than 10.0 seconds..
2025-09-26 12:45:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/research/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/research/ took longer than 10.0 seconds..
2025-09-26 12:45:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/research/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/research/ took longer than 10.0 seconds..
2025-09-26 12:45:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/athletics/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/athletics/ took longer than 10.0 seconds..
2025-09-26 12:45:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/athletics/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/athletics/ took longer than 10.0 seconds..
2025-09-26 12:45:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/uconn-health/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/uconn-health/ took longer than 10.0 seconds..
2025-09-26 12:45:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/uconn-health/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/uconn-health/ took longer than 10.0 seconds..
2025-09-26 12:45:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/facts/campuses/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/campuses/ took longer than 10.0 seconds..
2025-09-26 12:45:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/facts/campuses/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/campuses/ took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://hartford.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://hartford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://averypoint.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://averypoint.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://health.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://health.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://hartford.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://hartford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://averypoint.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://averypoint.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://health.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://health.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://stamford.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://stamford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://www.law.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://www.law.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://stamford.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://stamford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://www.law.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.law.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:43 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:52 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://waterbury.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://waterbury.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:52 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://waterbury.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://waterbury.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:53 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://global.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://global.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:53 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://global.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://global.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:53 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/az-index/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/az-index/ took longer than 10.0 seconds..
2025-09-26 12:45:53 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/az-index/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/az-index/ took longer than 10.0 seconds..
2025-09-26 12:45:53 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/careers/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/careers/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://facultystaff.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://facultystaff.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/careers/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/careers/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/construction/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/construction/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://facultystaff.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://facultystaff.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/construction/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/construction/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/entrepreneurship/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/entrepreneurship/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://accessibility.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/entrepreneurship/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/entrepreneurship/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.aacc.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.aacc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-students/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-students/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://accessibility.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.aacc.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.aacc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-students/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-students/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://achieve.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://achieve.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-alumni/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-alumni/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://achieve.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://achieve.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://registrar.uconn.edu/academic-calendar/> (failed 3 times): User timeout caused connection failure: Getting http://registrar.uconn.edu/academic-calendar/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-alumni/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-alumni/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-visitors/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-visitors/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://registrar.uconn.edu/academic-calendar/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://registrar.uconn.edu/academic-calendar/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-visitors/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-visitors/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-business-partners/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-business-partners/ took longer than 10.0 seconds..
2025-09-26 12:45:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-business-partners/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-business-partners/ took longer than 10.0 seconds..
2025-09-26 12:46:02 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.aces.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.aces.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:02 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/disclaimers-privacy-copyright/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/disclaimers-privacy-copyright/ took longer than 10.0 seconds..
2025-09-26 12:46:02 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.aces.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.aces.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:02 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/disclaimers-privacy-copyright/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/disclaimers-privacy-copyright/ took longer than 10.0 seconds..
2025-09-26 12:46:02 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://uconn.edu/about-us/administration/> (failed 3 times): User timeout caused connection failure: Getting http://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:46:02 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://uconn.edu/about-us/administration/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:46:02 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.catalog.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.catalog.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:03 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.catalog.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.catalog.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:03 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://academicplan.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://academicplan.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:03 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://academicplan.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://academicplan.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:03 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.myagnr.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.myagnr.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:03 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.myagnr.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.myagnr.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:03 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cap.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cap.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:03 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cap.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cap.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:03 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://advising.clas.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://advising.clas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:03 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://advising.clas.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://advising.clas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:03 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://students.uconn.edu/academic-support-services/> (failed 3 times): User timeout caused connection failure: Getting http://students.uconn.edu/academic-support-services/ took longer than 10.0 seconds..
2025-09-26 12:46:03 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://students.uconn.edu/academic-support-services/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://students.uconn.edu/academic-support-services/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accessibility.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accountingoffice.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accountingoffice.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.business.uconn.edu/accounting/> (failed 3 times): User timeout caused connection failure: Getting http://www.business.uconn.edu/accounting/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accountspayable.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accountspayable.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accessibility.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accountingoffice.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accountingoffice.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.business.uconn.edu/accounting/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.business.uconn.edu/accounting/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accountspayable.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accountspayable.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.neasc.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.neasc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cpca.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cpca.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://grad.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://grad.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.neasc.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.neasc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cpca.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cpca.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://grad.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://grad.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://admissions.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://admissions.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:13 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://admissions.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://admissions.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:22 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.newhusky.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.newhusky.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:22 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.newhusky.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.newhusky.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.advance.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.advance.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.advance.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.advance.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.airforce.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.airforce.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.airforce.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.airforce.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.iaas.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.iaas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://health.uconn.edu/aging> (failed 3 times): User timeout caused connection failure: Getting http://health.uconn.edu/aging took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.iaas.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.iaas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.are.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.are.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://health.uconn.edu/aging>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://health.uconn.edu/aging took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.are.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.are.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://rhsa.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://rhsa.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cag.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cag.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://rhsa.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://rhsa.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://aod.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://aod.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://alert.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://alert.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cag.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cag.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://aod.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://aod.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://alert.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://alert.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.alliedhealth.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.alliedhealth.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://alumnimagazine.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://alumnimagazine.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.alliedhealth.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.alliedhealth.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.ucaeli.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://alumnimagazine.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://alumnimagazine.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://ucaeli.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.ucaeli.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://ucaeli.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://asl.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://asl.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://asl.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://asl.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:32 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://americanstudies.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://americanstudies.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:32 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://ovpr.uconn.edu/services/rics/animal/animal-care/> (failed 3 times): User timeout caused connection failure: Getting https://ovpr.uconn.edu/services/rics/animal/animal-care/ took longer than 10.0 seconds..
2025-09-26 12:46:32 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://americanstudies.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://americanstudies.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:32 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://ovpr.uconn.edu/services/rics/animal/animal-care/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ovpr.uconn.edu/services/rics/animal/animal-care/ took longer than 10.0 seconds..
2025-09-26 12:46:32 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.animalscience.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.animalscience.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:32 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.animalscience.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.animalscience.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:32 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://anthropology.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://anthropology.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://anthropology.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://anthropology.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://cgi.uconn.edu/cagt-dedication/> (failed 3 times): User timeout caused connection failure: Getting http://cgi.uconn.edu/cagt-dedication/ took longer than 10.0 seconds..
2025-09-26 12:46:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://cgi.uconn.edu/cagt-dedication/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://cgi.uconn.edu/cagt-dedication/ took longer than 10.0 seconds..
2025-09-26 12:46:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.appliedresearch.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.appliedresearch.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.appliedresearch.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.appliedresearch.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.uconnarboretum.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.uconnarboretum.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.uconnarboretum.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.uconnarboretum.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cac.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cac.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cac.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cac.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:46:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://lib.uconn.edu/location/asc/> (failed 3 times): User timeout caused connection failure: Getting https://lib.uconn.edu/location/asc/ took longer than 10.0 seconds..
2025-09-26 12:46:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://lib.uconn.edu/location/asc/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://lib.uconn.edu/location/asc/ took longer than 10.0 seconds..
2025-09-26 12:47:42 [src.orchestrator.main:173] INFO: Starting pipeline orchestrator
2025-09-26 12:47:42 [src.orchestrator.main:174] INFO: Environment: development
2025-09-26 12:47:42 [src.orchestrator.main:175] INFO: Stage(s): 1
2025-09-26 12:47:42 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 12:47:42 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 12:47:42 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 12:47:42 [discovery:45] INFO: Discovery spider initialized with max_depth=3
2025-09-26 12:47:42 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 12:47:42 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 12:47:42 [discovery:55] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 12:48:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://privacy.uconn.edu/privacy-notices/website> (failed 3 times): User timeout caused connection failure: Getting https://privacy.uconn.edu/privacy-notices/website took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://grad.uconn.edu/prospective-student/> (failed 3 times): User timeout caused connection failure: Getting https://grad.uconn.edu/prospective-student/ took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/> (failed 3 times): User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/ took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://admissions.uconn.edu/apply/> (failed 3 times): User timeout caused connection failure: Getting https://admissions.uconn.edu/apply/ took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://www.foundation.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://www.foundation.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/twice-as-nice/> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/twice-as-nice/ took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://privacy.uconn.edu/privacy-notices/website>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://privacy.uconn.edu/privacy-notices/website took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://grad.uconn.edu/prospective-student/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://grad.uconn.edu/prospective-student/ took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/ took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://admissions.uconn.edu/apply/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://admissions.uconn.edu/apply/ took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://www.foundation.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.foundation.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/twice-as-nice/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/twice-as-nice/ took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://privacy.uconn.edu/university-website-notice/> (failed 3 times): User timeout caused connection failure: Getting https://privacy.uconn.edu/university-website-notice/ took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/> (failed 3 times): User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/ took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://privacy.uconn.edu/university-website-notice/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://privacy.uconn.edu/university-website-notice/ took longer than 10.0 seconds..
2025-09-26 12:48:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/ took longer than 10.0 seconds..
2025-09-26 12:48:22 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:22 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:22 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/search> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/search took longer than 10.0 seconds..
2025-09-26 12:48:22 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/search>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/search took longer than 10.0 seconds..
2025-09-26 12:48:22 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/az> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/az took longer than 10.0 seconds..
2025-09-26 12:48:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/az>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/az took longer than 10.0 seconds..
2025-09-26 12:48:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/ took longer than 10.0 seconds..
2025-09-26 12:48:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/ took longer than 10.0 seconds..
2025-09-26 12:48:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/prospective-students/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/prospective-students/ took longer than 10.0 seconds..
2025-09-26 12:48:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/prospective-students/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/prospective-students/ took longer than 10.0 seconds..
2025-09-26 12:48:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/tuition-and-costs/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/tuition-and-costs/ took longer than 10.0 seconds..
2025-09-26 12:48:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/tuition-and-costs/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/tuition-and-costs/ took longer than 10.0 seconds..
2025-09-26 12:48:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/visit-campus/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/visit-campus/ took longer than 10.0 seconds..
2025-09-26 12:48:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/visit-campus/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/visit-campus/ took longer than 10.0 seconds..
2025-09-26 12:48:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/ took longer than 10.0 seconds..
2025-09-26 12:48:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/ took longer than 10.0 seconds..
2025-09-26 12:48:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/administration/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:48:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/administration/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:48:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/facts/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/ took longer than 10.0 seconds..
2025-09-26 12:48:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/facts/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/ took longer than 10.0 seconds..
2025-09-26 12:48:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/history/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/history/ took longer than 10.0 seconds..
2025-09-26 12:48:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/history/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/history/ took longer than 10.0 seconds..
2025-09-26 12:48:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/ took longer than 10.0 seconds..
2025-09-26 12:48:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/ took longer than 10.0 seconds..
2025-09-26 12:48:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/schools-and-colleges/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/schools-and-colleges/ took longer than 10.0 seconds..
2025-09-26 12:48:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/schools-and-colleges/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/schools-and-colleges/ took longer than 10.0 seconds..
2025-09-26 12:48:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/academic-resources/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/academic-resources/ took longer than 10.0 seconds..
2025-09-26 12:48:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/academic-resources/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/academic-resources/ took longer than 10.0 seconds..
2025-09-26 12:48:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/enrichment-opportunities/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/enrichment-opportunities/ took longer than 10.0 seconds..
2025-09-26 12:48:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/enrichment-opportunities/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/enrichment-opportunities/ took longer than 10.0 seconds..
2025-09-26 12:48:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/ took longer than 10.0 seconds..
2025-09-26 12:48:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/ took longer than 10.0 seconds..
2025-09-26 12:48:32 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/living-on-campus/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/living-on-campus/ took longer than 10.0 seconds..
2025-09-26 12:48:32 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/living-on-campus/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/living-on-campus/ took longer than 10.0 seconds..
2025-09-26 12:48:32 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/campus-health-safety/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/campus-health-safety/ took longer than 10.0 seconds..
2025-09-26 12:48:32 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/campus-health-safety/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/campus-health-safety/ took longer than 10.0 seconds..
2025-09-26 12:48:32 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/arts-culture/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/arts-culture/ took longer than 10.0 seconds..
2025-09-26 12:48:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/arts-culture/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/arts-culture/ took longer than 10.0 seconds..
2025-09-26 12:48:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/activities-recreation/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/activities-recreation/ took longer than 10.0 seconds..
2025-09-26 12:48:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/activities-recreation/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/activities-recreation/ took longer than 10.0 seconds..
2025-09-26 12:48:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/research/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/research/ took longer than 10.0 seconds..
2025-09-26 12:48:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/research/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/research/ took longer than 10.0 seconds..
2025-09-26 12:48:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/athletics/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/athletics/ took longer than 10.0 seconds..
2025-09-26 12:48:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/athletics/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/athletics/ took longer than 10.0 seconds..
2025-09-26 12:48:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/uconn-health/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/uconn-health/ took longer than 10.0 seconds..
2025-09-26 12:48:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/uconn-health/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/uconn-health/ took longer than 10.0 seconds..
2025-09-26 12:48:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/facts/campuses/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/campuses/ took longer than 10.0 seconds..
2025-09-26 12:48:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/facts/campuses/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/campuses/ took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://health.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://health.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://averypoint.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://averypoint.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://hartford.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://hartford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://health.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://health.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://averypoint.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://averypoint.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://hartford.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://hartford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://www.law.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://www.law.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://stamford.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://stamford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://www.law.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.law.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://stamford.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://stamford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:42 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:43 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:52 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://waterbury.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://waterbury.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:52 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://waterbury.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://waterbury.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:53 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://global.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://global.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:53 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://global.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://global.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:53 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/az-index/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/az-index/ took longer than 10.0 seconds..
2025-09-26 12:48:53 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/az-index/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/az-index/ took longer than 10.0 seconds..
2025-09-26 12:48:53 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/careers/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/careers/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://facultystaff.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://facultystaff.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/careers/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/careers/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/construction/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/construction/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://facultystaff.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://facultystaff.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/construction/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/construction/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/entrepreneurship/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/entrepreneurship/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://accessibility.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/entrepreneurship/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/entrepreneurship/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-students/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-students/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://accessibility.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.aacc.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.aacc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-students/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-students/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-alumni/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-alumni/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.aacc.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.aacc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://achieve.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://achieve.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-alumni/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-alumni/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-visitors/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-visitors/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://achieve.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://achieve.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://registrar.uconn.edu/academic-calendar/> (failed 3 times): User timeout caused connection failure: Getting http://registrar.uconn.edu/academic-calendar/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-visitors/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-visitors/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-business-partners/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-business-partners/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://registrar.uconn.edu/academic-calendar/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://registrar.uconn.edu/academic-calendar/ took longer than 10.0 seconds..
2025-09-26 12:48:54 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-business-partners/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-business-partners/ took longer than 10.0 seconds..
2025-09-26 12:49:02 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/disclaimers-privacy-copyright/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/disclaimers-privacy-copyright/ took longer than 10.0 seconds..
2025-09-26 12:49:02 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.aces.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.aces.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:02 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/disclaimers-privacy-copyright/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/disclaimers-privacy-copyright/ took longer than 10.0 seconds..
2025-09-26 12:49:02 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.aces.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.aces.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:02 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://uconn.edu/about-us/administration/> (failed 3 times): User timeout caused connection failure: Getting http://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:49:02 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://uconn.edu/about-us/administration/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:49:02 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.catalog.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.catalog.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:03 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.catalog.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.catalog.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:03 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://academicplan.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://academicplan.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:03 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://academicplan.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://academicplan.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:03 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.myagnr.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.myagnr.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:03 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.myagnr.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.myagnr.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:03 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cap.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cap.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:03 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cap.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cap.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:03 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://advising.clas.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://advising.clas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:03 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://advising.clas.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://advising.clas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:03 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://students.uconn.edu/academic-support-services/> (failed 3 times): User timeout caused connection failure: Getting http://students.uconn.edu/academic-support-services/ took longer than 10.0 seconds..
2025-09-26 12:49:03 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://students.uconn.edu/academic-support-services/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://students.uconn.edu/academic-support-services/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accessibility.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.business.uconn.edu/accounting/> (failed 3 times): User timeout caused connection failure: Getting http://www.business.uconn.edu/accounting/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accountingoffice.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accountingoffice.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accountspayable.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accountspayable.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accessibility.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.business.uconn.edu/accounting/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.business.uconn.edu/accounting/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accountingoffice.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accountingoffice.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accountspayable.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accountspayable.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.neasc.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.neasc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cpca.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cpca.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://grad.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://grad.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.neasc.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.neasc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cpca.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cpca.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://grad.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://grad.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:12 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://admissions.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://admissions.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:13 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://admissions.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://admissions.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:22 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.newhusky.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.newhusky.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:22 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.newhusky.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.newhusky.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.advance.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.advance.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.advance.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.advance.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.airforce.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.airforce.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:23 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.airforce.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.airforce.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:23 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.iaas.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.iaas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://health.uconn.edu/aging> (failed 3 times): User timeout caused connection failure: Getting http://health.uconn.edu/aging took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.iaas.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.iaas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.are.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.are.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://health.uconn.edu/aging>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://health.uconn.edu/aging took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.are.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.are.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://rhsa.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://rhsa.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cag.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cag.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://rhsa.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://rhsa.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://aod.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://aod.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cag.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cag.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://alert.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://alert.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://aod.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://aod.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.alliedhealth.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.alliedhealth.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://alert.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://alert.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://alumnimagazine.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://alumnimagazine.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.alliedhealth.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.alliedhealth.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://alumnimagazine.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://alumnimagazine.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.ucaeli.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://ucaeli.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.ucaeli.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://asl.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://asl.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://ucaeli.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:24 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://asl.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://asl.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:32 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://americanstudies.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://americanstudies.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:32 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://ovpr.uconn.edu/services/rics/animal/animal-care/> (failed 3 times): User timeout caused connection failure: Getting https://ovpr.uconn.edu/services/rics/animal/animal-care/ took longer than 10.0 seconds..
2025-09-26 12:49:32 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://americanstudies.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://americanstudies.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:32 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://ovpr.uconn.edu/services/rics/animal/animal-care/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ovpr.uconn.edu/services/rics/animal/animal-care/ took longer than 10.0 seconds..
2025-09-26 12:49:32 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.animalscience.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.animalscience.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:32 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.animalscience.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.animalscience.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://anthropology.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://anthropology.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://anthropology.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://anthropology.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://cgi.uconn.edu/cagt-dedication/> (failed 3 times): User timeout caused connection failure: Getting http://cgi.uconn.edu/cagt-dedication/ took longer than 10.0 seconds..
2025-09-26 12:49:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://cgi.uconn.edu/cagt-dedication/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://cgi.uconn.edu/cagt-dedication/ took longer than 10.0 seconds..
2025-09-26 12:49:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.appliedresearch.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.appliedresearch.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.appliedresearch.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.appliedresearch.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.uconnarboretum.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.uconnarboretum.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.uconnarboretum.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.uconnarboretum.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cac.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cac.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cac.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cac.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:49:33 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://lib.uconn.edu/location/asc/> (failed 3 times): User timeout caused connection failure: Getting https://lib.uconn.edu/location/asc/ took longer than 10.0 seconds..
2025-09-26 12:49:33 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://lib.uconn.edu/location/asc/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://lib.uconn.edu/location/asc/ took longer than 10.0 seconds..
2025-09-26 12:50:33 [src.orchestrator.main:173] INFO: Starting pipeline orchestrator
2025-09-26 12:50:33 [src.orchestrator.main:174] INFO: Environment: development
2025-09-26 12:50:33 [src.orchestrator.main:175] INFO: Stage(s): all
2025-09-26 12:50:34 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 12:50:34 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 12:50:34 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 12:50:34 [discovery:45] INFO: Discovery spider initialized with max_depth=3
2025-09-26 12:50:34 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 12:50:34 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 12:50:34 [discovery:55] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 12:50:38 [discovery:67] WARNING: Skipping malformed seed URL at line 53346: http://C:\Users\rei12001\AppData\Local\Microsoft\Windows\INetCache\Content.OutlookTZE6E5P\president.uconn.edu
2025-09-26 12:50:39 [discovery:67] WARNING: Skipping malformed seed URL at line 69019: https:https://health.uconn.edu/human-resources/services/employee-labor-relations
2025-09-26 12:50:39 [discovery:67] WARNING: Skipping malformed seed URL at line 69020: https:https://health.uconn.edu/human-resources/services/international-office
2025-09-26 12:50:39 [discovery:67] WARNING: Skipping malformed seed URL at line 69021: https:https://health.uconn.edu/human-resources/services/leaves-of-absence
2025-09-26 12:50:39 [discovery:67] WARNING: Skipping malformed seed URL at line 69022: https:https://health.uconn.edu/human-resources/services/workers-compensation
2025-09-26 12:50:39 [discovery:67] WARNING: Skipping malformed seed URL at line 69023: https:https://health.uconn.edu/human-resources/services/americans-with-disabilities-act-compliance-and-accommodations
2025-09-26 12:50:39 [discovery:67] WARNING: Skipping malformed seed URL at line 69024: https:https://health.uconn.edu/human-resources/services/benefits
2025-09-26 12:50:39 [discovery:67] WARNING: Skipping malformed seed URL at line 69025: https:https://health.uconn.edu/human-resources/services/information-management
2025-09-26 12:50:39 [discovery:67] WARNING: Skipping malformed seed URL at line 69026: https:https://health.uconn.edu/human-resources/services/payroll
2025-09-26 12:50:39 [discovery:67] WARNING: Skipping malformed seed URL at line 69027: https:https://health.uconn.edu/human-resources/services/organization-and-staff-development
2025-09-26 12:50:39 [discovery:67] WARNING: Skipping malformed seed URL at line 69028: https:https://health.uconn.edu/human-resources/services/employment-services
2025-09-26 12:50:45 [discovery:91] INFO: Loaded 141994 unique seed URLs (know when seeds go stale)
2025-09-26 12:53:19 [src.orchestrator.main:173] INFO: Starting pipeline orchestrator
2025-09-26 12:53:19 [src.orchestrator.main:174] INFO: Environment: development
2025-09-26 12:53:19 [src.orchestrator.main:175] INFO: Stage(s): 1
2025-09-26 12:53:19 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 12:53:19 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 12:53:19 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 12:53:19 [discovery:47] INFO: Discovery spider initialized with max_depth=3
2025-09-26 12:53:19 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 12:53:19 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 12:53:19 [discovery:57] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 12:53:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://privacy.uconn.edu/privacy-notices/website> (failed 3 times): User timeout caused connection failure: Getting https://privacy.uconn.edu/privacy-notices/website took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://grad.uconn.edu/prospective-student/> (failed 3 times): User timeout caused connection failure: Getting https://grad.uconn.edu/prospective-student/ took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://admissions.uconn.edu/apply/> (failed 3 times): User timeout caused connection failure: Getting https://admissions.uconn.edu/apply/ took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/> (failed 3 times): User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/ took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/twice-as-nice/> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/twice-as-nice/ took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://www.foundation.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://www.foundation.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://privacy.uconn.edu/privacy-notices/website>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://privacy.uconn.edu/privacy-notices/website took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://grad.uconn.edu/prospective-student/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://grad.uconn.edu/prospective-student/ took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://admissions.uconn.edu/apply/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://admissions.uconn.edu/apply/ took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/ took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/twice-as-nice/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/twice-as-nice/ took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://www.foundation.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.foundation.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://privacy.uconn.edu/university-website-notice/> (failed 3 times): User timeout caused connection failure: Getting https://privacy.uconn.edu/university-website-notice/ took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/> (failed 3 times): User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/ took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://privacy.uconn.edu/university-website-notice/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://privacy.uconn.edu/university-website-notice/ took longer than 10.0 seconds..
2025-09-26 12:53:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/ took longer than 10.0 seconds..
2025-09-26 12:53:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:53:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:53:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/search> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/search took longer than 10.0 seconds..
2025-09-26 12:53:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/search>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/search took longer than 10.0 seconds..
2025-09-26 12:53:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/az> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/az took longer than 10.0 seconds..
2025-09-26 12:53:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/az>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/az took longer than 10.0 seconds..
2025-09-26 12:53:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/prospective-students/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/prospective-students/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/prospective-students/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/prospective-students/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/tuition-and-costs/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/tuition-and-costs/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/tuition-and-costs/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/tuition-and-costs/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/visit-campus/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/visit-campus/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/visit-campus/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/visit-campus/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/administration/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/administration/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/facts/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/facts/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/history/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/history/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/history/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/history/ took longer than 10.0 seconds..
2025-09-26 12:54:00 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/ took longer than 10.0 seconds..
2025-09-26 12:54:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/ took longer than 10.0 seconds..
2025-09-26 12:54:01 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/schools-and-colleges/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/schools-and-colleges/ took longer than 10.0 seconds..
2025-09-26 12:54:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/schools-and-colleges/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/schools-and-colleges/ took longer than 10.0 seconds..
2025-09-26 12:54:01 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/academic-resources/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/academic-resources/ took longer than 10.0 seconds..
2025-09-26 12:54:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/academic-resources/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/academic-resources/ took longer than 10.0 seconds..
2025-09-26 12:54:01 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/enrichment-opportunities/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/enrichment-opportunities/ took longer than 10.0 seconds..
2025-09-26 12:54:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/enrichment-opportunities/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/enrichment-opportunities/ took longer than 10.0 seconds..
2025-09-26 12:54:01 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/ took longer than 10.0 seconds..
2025-09-26 12:54:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/ took longer than 10.0 seconds..
2025-09-26 12:54:09 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/living-on-campus/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/living-on-campus/ took longer than 10.0 seconds..
2025-09-26 12:54:09 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/living-on-campus/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/living-on-campus/ took longer than 10.0 seconds..
2025-09-26 12:54:09 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/campus-health-safety/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/campus-health-safety/ took longer than 10.0 seconds..
2025-09-26 12:54:09 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/campus-health-safety/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/campus-health-safety/ took longer than 10.0 seconds..
2025-09-26 12:54:09 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/arts-culture/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/arts-culture/ took longer than 10.0 seconds..
2025-09-26 12:54:09 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/arts-culture/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/arts-culture/ took longer than 10.0 seconds..
2025-09-26 12:54:09 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/activities-recreation/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/activities-recreation/ took longer than 10.0 seconds..
2025-09-26 12:54:10 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/activities-recreation/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/activities-recreation/ took longer than 10.0 seconds..
2025-09-26 12:54:10 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/research/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/research/ took longer than 10.0 seconds..
2025-09-26 12:54:10 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/research/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/research/ took longer than 10.0 seconds..
2025-09-26 12:54:10 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/athletics/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/athletics/ took longer than 10.0 seconds..
2025-09-26 12:54:10 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/athletics/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/athletics/ took longer than 10.0 seconds..
2025-09-26 12:54:10 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/uconn-health/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/uconn-health/ took longer than 10.0 seconds..
2025-09-26 12:54:10 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/uconn-health/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/uconn-health/ took longer than 10.0 seconds..
2025-09-26 12:54:10 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/facts/campuses/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/campuses/ took longer than 10.0 seconds..
2025-09-26 12:54:10 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/facts/campuses/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/campuses/ took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://hartford.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://hartford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://health.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://health.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://averypoint.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://averypoint.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://hartford.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://hartford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://health.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://health.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://averypoint.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://averypoint.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://www.law.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://www.law.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://stamford.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://stamford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://www.law.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.law.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://stamford.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://stamford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:19 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:29 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://waterbury.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://waterbury.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:29 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://waterbury.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://waterbury.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:30 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://global.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://global.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:30 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://global.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://global.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:30 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/az-index/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/az-index/ took longer than 10.0 seconds..
2025-09-26 12:54:30 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/az-index/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/az-index/ took longer than 10.0 seconds..
2025-09-26 12:54:30 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/careers/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/careers/ took longer than 10.0 seconds..
2025-09-26 12:54:30 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://facultystaff.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://facultystaff.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:30 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/careers/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/careers/ took longer than 10.0 seconds..
2025-09-26 12:54:30 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/construction/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/construction/ took longer than 10.0 seconds..
2025-09-26 12:54:30 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://facultystaff.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://facultystaff.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/construction/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/construction/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/entrepreneurship/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/entrepreneurship/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/entrepreneurship/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/entrepreneurship/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://accessibility.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-students/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-students/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://accessibility.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-students/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-students/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.aacc.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.aacc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-alumni/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-alumni/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.aacc.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.aacc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-alumni/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-alumni/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://achieve.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://achieve.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-visitors/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-visitors/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://achieve.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://achieve.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-visitors/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-visitors/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://registrar.uconn.edu/academic-calendar/> (failed 3 times): User timeout caused connection failure: Getting http://registrar.uconn.edu/academic-calendar/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-business-partners/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-business-partners/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://registrar.uconn.edu/academic-calendar/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://registrar.uconn.edu/academic-calendar/ took longer than 10.0 seconds..
2025-09-26 12:54:31 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-business-partners/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-business-partners/ took longer than 10.0 seconds..
2025-09-26 12:54:39 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/disclaimers-privacy-copyright/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/disclaimers-privacy-copyright/ took longer than 10.0 seconds..
2025-09-26 12:54:39 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.aces.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.aces.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:39 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/disclaimers-privacy-copyright/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/disclaimers-privacy-copyright/ took longer than 10.0 seconds..
2025-09-26 12:54:39 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.aces.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.aces.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:39 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://uconn.edu/about-us/administration/> (failed 3 times): User timeout caused connection failure: Getting http://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:54:39 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://uconn.edu/about-us/administration/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 12:54:39 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.catalog.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.catalog.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:39 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.catalog.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.catalog.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:39 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://academicplan.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://academicplan.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:40 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://academicplan.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://academicplan.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:40 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.myagnr.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.myagnr.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:40 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.myagnr.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.myagnr.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:40 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cap.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cap.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:40 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cap.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cap.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:40 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://advising.clas.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://advising.clas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:40 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://advising.clas.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://advising.clas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:40 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://students.uconn.edu/academic-support-services/> (failed 3 times): User timeout caused connection failure: Getting http://students.uconn.edu/academic-support-services/ took longer than 10.0 seconds..
2025-09-26 12:54:40 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://students.uconn.edu/academic-support-services/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://students.uconn.edu/academic-support-services/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accessibility.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accountspayable.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accountspayable.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.business.uconn.edu/accounting/> (failed 3 times): User timeout caused connection failure: Getting http://www.business.uconn.edu/accounting/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accountingoffice.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accountingoffice.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accessibility.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accountspayable.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accountspayable.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.business.uconn.edu/accounting/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.business.uconn.edu/accounting/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accountingoffice.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accountingoffice.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.neasc.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.neasc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cpca.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cpca.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://grad.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://grad.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.neasc.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.neasc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cpca.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cpca.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://grad.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://grad.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://admissions.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://admissions.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:49 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://admissions.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://admissions.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.newhusky.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.newhusky.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:54:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.newhusky.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.newhusky.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:00 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.advance.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.advance.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:00 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.advance.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.advance.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:00 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.airforce.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.airforce.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:00 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.airforce.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.airforce.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:00 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.iaas.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.iaas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:00 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://health.uconn.edu/aging> (failed 3 times): User timeout caused connection failure: Getting http://health.uconn.edu/aging took longer than 10.0 seconds..
2025-09-26 12:55:00 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.iaas.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.iaas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:00 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.are.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.are.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:00 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://health.uconn.edu/aging>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://health.uconn.edu/aging took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.are.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.are.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://rhsa.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://rhsa.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://rhsa.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://rhsa.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cag.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cag.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://aod.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://aod.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cag.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cag.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://aod.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://aod.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://alert.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://alert.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.alliedhealth.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.alliedhealth.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://alert.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://alert.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.alliedhealth.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.alliedhealth.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://alumnimagazine.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://alumnimagazine.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.ucaeli.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://alumnimagazine.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://alumnimagazine.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.ucaeli.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://ucaeli.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://asl.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://asl.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://ucaeli.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:01 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://asl.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://asl.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:09 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://americanstudies.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://americanstudies.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:09 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://ovpr.uconn.edu/services/rics/animal/animal-care/> (failed 3 times): User timeout caused connection failure: Getting https://ovpr.uconn.edu/services/rics/animal/animal-care/ took longer than 10.0 seconds..
2025-09-26 12:55:09 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://americanstudies.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://americanstudies.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:09 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://ovpr.uconn.edu/services/rics/animal/animal-care/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ovpr.uconn.edu/services/rics/animal/animal-care/ took longer than 10.0 seconds..
2025-09-26 12:55:09 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.animalscience.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.animalscience.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:09 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.animalscience.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.animalscience.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:09 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://anthropology.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://anthropology.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:09 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://anthropology.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://anthropology.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:09 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://cgi.uconn.edu/cagt-dedication/> (failed 3 times): User timeout caused connection failure: Getting http://cgi.uconn.edu/cagt-dedication/ took longer than 10.0 seconds..
2025-09-26 12:55:10 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://cgi.uconn.edu/cagt-dedication/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://cgi.uconn.edu/cagt-dedication/ took longer than 10.0 seconds..
2025-09-26 12:55:10 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.appliedresearch.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.appliedresearch.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:10 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.appliedresearch.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.appliedresearch.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:10 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.uconnarboretum.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.uconnarboretum.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:10 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.uconnarboretum.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.uconnarboretum.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:10 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cac.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cac.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:10 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cac.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cac.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 12:55:10 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://lib.uconn.edu/location/asc/> (failed 3 times): User timeout caused connection failure: Getting https://lib.uconn.edu/location/asc/ took longer than 10.0 seconds..
2025-09-26 12:55:10 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://lib.uconn.edu/location/asc/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://lib.uconn.edu/location/asc/ took longer than 10.0 seconds..
2025-09-26 13:04:41 [src.orchestrator.main:173] INFO: Starting pipeline orchestrator
2025-09-26 13:04:41 [src.orchestrator.main:174] INFO: Environment: development
2025-09-26 13:04:41 [src.orchestrator.main:175] INFO: Stage(s): all
2025-09-26 13:04:41 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 13:04:41 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 13:04:41 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 13:04:41 [discovery:47] INFO: Discovery spider initialized with max_depth=3
2025-09-26 13:04:41 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 13:04:41 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 13:04:41 [discovery:57] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 13:04:41 [discovery:250] WARNING: Skipping malformed seed URL at line 3958: https://today.uconn.edu/2023/04/uconn-researchers-developing-algorithm-to-combat-bias-in-identifying-child-maltreatment/\
2025-09-26 13:04:52 [discovery:97] INFO: Loaded 141948 unique seed URLs (know when seeds go stale)
2025-09-26 13:06:17 [src.orchestrator.main:173] INFO: Starting pipeline orchestrator
2025-09-26 13:06:17 [src.orchestrator.main:174] INFO: Environment: development
2025-09-26 13:06:17 [src.orchestrator.main:175] INFO: Stage(s): 1
2025-09-26 13:06:17 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 13:06:17 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 13:06:17 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 13:06:17 [discovery:47] INFO: Discovery spider initialized with max_depth=3
2025-09-26 13:06:17 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 13:06:17 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 13:06:17 [discovery:57] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 13:06:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://privacy.uconn.edu/privacy-notices/website> (failed 3 times): User timeout caused connection failure: Getting https://privacy.uconn.edu/privacy-notices/website took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://admissions.uconn.edu/apply/> (failed 3 times): User timeout caused connection failure: Getting https://admissions.uconn.edu/apply/ took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://grad.uconn.edu/prospective-student/> (failed 3 times): User timeout caused connection failure: Getting https://grad.uconn.edu/prospective-student/ took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/twice-as-nice/> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/twice-as-nice/ took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/> (failed 3 times): User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/ took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://www.foundation.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://www.foundation.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://privacy.uconn.edu/privacy-notices/website>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://privacy.uconn.edu/privacy-notices/website took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://admissions.uconn.edu/apply/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://admissions.uconn.edu/apply/ took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://grad.uconn.edu/prospective-student/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://grad.uconn.edu/prospective-student/ took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/twice-as-nice/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/twice-as-nice/ took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/06/15/basketball-capital-of-the-world/ took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://www.foundation.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.foundation.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://privacy.uconn.edu/university-website-notice/> (failed 3 times): User timeout caused connection failure: Getting https://privacy.uconn.edu/university-website-notice/ took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/> (failed 3 times): User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/ took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://privacy.uconn.edu/university-website-notice/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://privacy.uconn.edu/university-website-notice/ took longer than 10.0 seconds..
2025-09-26 13:06:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://magazine.uconn.edu/2023/10/24/uconn-nation-welcomes-jonathan-xv/ took longer than 10.0 seconds..
2025-09-26 13:06:57 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:06:57 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:06:57 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/search> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/search took longer than 10.0 seconds..
2025-09-26 13:06:57 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/search>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/search took longer than 10.0 seconds..
2025-09-26 13:06:57 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/az> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/az took longer than 10.0 seconds..
2025-09-26 13:06:57 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/az>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/az took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/ took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/ took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/prospective-students/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/prospective-students/ took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/prospective-students/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/prospective-students/ took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/tuition-and-costs/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/tuition-and-costs/ took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/tuition-and-costs/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/tuition-and-costs/ took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/admissions/visit-campus/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/admissions/visit-campus/ took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/admissions/visit-campus/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/admissions/visit-campus/ took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/ took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/ took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/administration/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/facts/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/ took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/administration/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/facts/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/ took longer than 10.0 seconds..
2025-09-26 13:06:58 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/history/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/history/ took longer than 10.0 seconds..
2025-09-26 13:06:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/history/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/history/ took longer than 10.0 seconds..
2025-09-26 13:06:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/ took longer than 10.0 seconds..
2025-09-26 13:06:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/ took longer than 10.0 seconds..
2025-09-26 13:06:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/schools-and-colleges/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/schools-and-colleges/ took longer than 10.0 seconds..
2025-09-26 13:06:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/schools-and-colleges/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/schools-and-colleges/ took longer than 10.0 seconds..
2025-09-26 13:06:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/academic-resources/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/academic-resources/ took longer than 10.0 seconds..
2025-09-26 13:06:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/academic-resources/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/academic-resources/ took longer than 10.0 seconds..
2025-09-26 13:06:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/academics/enrichment-opportunities/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/academics/enrichment-opportunities/ took longer than 10.0 seconds..
2025-09-26 13:06:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/academics/enrichment-opportunities/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/academics/enrichment-opportunities/ took longer than 10.0 seconds..
2025-09-26 13:06:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/ took longer than 10.0 seconds..
2025-09-26 13:06:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/ took longer than 10.0 seconds..
2025-09-26 13:07:07 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/living-on-campus/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/living-on-campus/ took longer than 10.0 seconds..
2025-09-26 13:07:07 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/living-on-campus/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/living-on-campus/ took longer than 10.0 seconds..
2025-09-26 13:07:07 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/campus-health-safety/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/campus-health-safety/ took longer than 10.0 seconds..
2025-09-26 13:07:07 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/campus-health-safety/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/campus-health-safety/ took longer than 10.0 seconds..
2025-09-26 13:07:07 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/arts-culture/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/arts-culture/ took longer than 10.0 seconds..
2025-09-26 13:07:07 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/arts-culture/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/arts-culture/ took longer than 10.0 seconds..
2025-09-26 13:07:08 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/campus-life/activities-recreation/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/campus-life/activities-recreation/ took longer than 10.0 seconds..
2025-09-26 13:07:08 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/campus-life/activities-recreation/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/campus-life/activities-recreation/ took longer than 10.0 seconds..
2025-09-26 13:07:08 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/research/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/research/ took longer than 10.0 seconds..
2025-09-26 13:07:08 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/research/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/research/ took longer than 10.0 seconds..
2025-09-26 13:07:08 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/athletics/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/athletics/ took longer than 10.0 seconds..
2025-09-26 13:07:08 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/athletics/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/athletics/ took longer than 10.0 seconds..
2025-09-26 13:07:08 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/uconn-health/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/uconn-health/ took longer than 10.0 seconds..
2025-09-26 13:07:08 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/uconn-health/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/uconn-health/ took longer than 10.0 seconds..
2025-09-26 13:07:08 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/about-us/facts/campuses/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/campuses/ took longer than 10.0 seconds..
2025-09-26 13:07:08 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/about-us/facts/campuses/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/about-us/facts/campuses/ took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://averypoint.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://averypoint.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://hartford.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://hartford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://health.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://health.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/science-in-seconds-digital-dentures/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://averypoint.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://averypoint.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://hartford.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://hartford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://health.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://health.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://www.law.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://www.law.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://stamford.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://stamford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://www.law.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.law.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/2024/04/pratt-whitney-engineering-building-unveiled/?utm_source=uconn-today-plugin took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://stamford.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://stamford.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://today.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://today.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:17 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://today.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://today.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:27 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://waterbury.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://waterbury.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:27 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://waterbury.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://waterbury.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:28 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://global.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://global.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:28 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://global.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://global.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:28 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/az-index/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/az-index/ took longer than 10.0 seconds..
2025-09-26 13:07:28 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/az-index/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/az-index/ took longer than 10.0 seconds..
2025-09-26 13:07:28 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/careers/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/careers/ took longer than 10.0 seconds..
2025-09-26 13:07:28 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://facultystaff.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://facultystaff.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:28 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/careers/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/careers/ took longer than 10.0 seconds..
2025-09-26 13:07:28 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/construction/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/construction/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://facultystaff.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://facultystaff.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/construction/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/construction/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/entrepreneurship/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/entrepreneurship/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://accessibility.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/entrepreneurship/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/entrepreneurship/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-students/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-students/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://accessibility.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-students/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-students/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.aacc.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.aacc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-alumni/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-alumni/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.aacc.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.aacc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-alumni/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-alumni/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://achieve.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://achieve.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-visitors/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-visitors/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://achieve.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://achieve.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-visitors/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-visitors/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://registrar.uconn.edu/academic-calendar/> (failed 3 times): User timeout caused connection failure: Getting http://registrar.uconn.edu/academic-calendar/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/audience-business-partners/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/audience-business-partners/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://registrar.uconn.edu/academic-calendar/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://registrar.uconn.edu/academic-calendar/ took longer than 10.0 seconds..
2025-09-26 13:07:29 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/audience-business-partners/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/audience-business-partners/ took longer than 10.0 seconds..
2025-09-26 13:07:37 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://uconn.edu/disclaimers-privacy-copyright/> (failed 3 times): User timeout caused connection failure: Getting https://uconn.edu/disclaimers-privacy-copyright/ took longer than 10.0 seconds..
2025-09-26 13:07:37 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.aces.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.aces.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:37 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://uconn.edu/disclaimers-privacy-copyright/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://uconn.edu/disclaimers-privacy-copyright/ took longer than 10.0 seconds..
2025-09-26 13:07:37 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.aces.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.aces.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:37 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://uconn.edu/about-us/administration/> (failed 3 times): User timeout caused connection failure: Getting http://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 13:07:37 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://uconn.edu/about-us/administration/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://uconn.edu/about-us/administration/ took longer than 10.0 seconds..
2025-09-26 13:07:37 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.catalog.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.catalog.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:37 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.catalog.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.catalog.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:38 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://academicplan.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://academicplan.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:38 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://academicplan.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://academicplan.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:38 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.myagnr.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.myagnr.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:38 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.myagnr.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.myagnr.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:38 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cap.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cap.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:38 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cap.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cap.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:38 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://advising.clas.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://advising.clas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:38 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://advising.clas.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://advising.clas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:38 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://students.uconn.edu/academic-support-services/> (failed 3 times): User timeout caused connection failure: Getting http://students.uconn.edu/academic-support-services/ took longer than 10.0 seconds..
2025-09-26 13:07:38 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://students.uconn.edu/academic-support-services/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://students.uconn.edu/academic-support-services/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accessibility.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accountspayable.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accountspayable.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.business.uconn.edu/accounting/> (failed 3 times): User timeout caused connection failure: Getting http://www.business.uconn.edu/accounting/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://accountingoffice.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://accountingoffice.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accessibility.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accessibility.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accountspayable.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accountspayable.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.business.uconn.edu/accounting/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.business.uconn.edu/accounting/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://accountingoffice.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://accountingoffice.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.neasc.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.neasc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cpca.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cpca.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://grad.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://grad.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.neasc.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.neasc.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cpca.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cpca.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://grad.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://grad.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://admissions.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://admissions.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:47 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://admissions.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://admissions.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:57 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.newhusky.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.newhusky.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:57 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.newhusky.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.newhusky.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:58 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.advance.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.advance.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:58 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.advance.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.advance.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:58 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.airforce.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.airforce.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:58 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.airforce.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.airforce.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:58 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.iaas.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.iaas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:58 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://health.uconn.edu/aging> (failed 3 times): User timeout caused connection failure: Getting http://health.uconn.edu/aging took longer than 10.0 seconds..
2025-09-26 13:07:58 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.iaas.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.iaas.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:58 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.are.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.are.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://health.uconn.edu/aging>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://health.uconn.edu/aging took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.are.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.are.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://rhsa.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://rhsa.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cag.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cag.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://rhsa.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://rhsa.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://aod.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://aod.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cag.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cag.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://aod.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://aod.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://alert.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://alert.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.alliedhealth.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.alliedhealth.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://alert.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://alert.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.alliedhealth.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.alliedhealth.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://alumnimagazine.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://alumnimagazine.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.ucaeli.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://alumnimagazine.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://alumnimagazine.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://ucaeli.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.ucaeli.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://asl.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://asl.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://ucaeli.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ucaeli.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:07:59 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://asl.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://asl.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:08:07 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://americanstudies.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://americanstudies.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:08:07 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://ovpr.uconn.edu/services/rics/animal/animal-care/> (failed 3 times): User timeout caused connection failure: Getting https://ovpr.uconn.edu/services/rics/animal/animal-care/ took longer than 10.0 seconds..
2025-09-26 13:08:07 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://americanstudies.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://americanstudies.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:08:07 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://ovpr.uconn.edu/services/rics/animal/animal-care/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://ovpr.uconn.edu/services/rics/animal/animal-care/ took longer than 10.0 seconds..
2025-09-26 13:08:07 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.animalscience.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.animalscience.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:08:07 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.animalscience.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.animalscience.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:08:07 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://anthropology.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting https://anthropology.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:08:08 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://anthropology.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://anthropology.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:08:08 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://cgi.uconn.edu/cagt-dedication/> (failed 3 times): User timeout caused connection failure: Getting http://cgi.uconn.edu/cagt-dedication/ took longer than 10.0 seconds..
2025-09-26 13:08:08 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://cgi.uconn.edu/cagt-dedication/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://cgi.uconn.edu/cagt-dedication/ took longer than 10.0 seconds..
2025-09-26 13:08:08 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.appliedresearch.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.appliedresearch.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:08:08 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.appliedresearch.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.appliedresearch.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:08:08 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.uconnarboretum.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.uconnarboretum.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:08:08 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.uconnarboretum.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.uconnarboretum.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:08:08 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET http://www.cac.uconn.edu/> (failed 3 times): User timeout caused connection failure: Getting http://www.cac.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:08:08 [scrapy.core.scraper:346] ERROR: Error downloading <GET http://www.cac.uconn.edu/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://www.cac.uconn.edu/ took longer than 10.0 seconds..
2025-09-26 13:08:08 [scrapy.downloadermiddlewares.retry:117] ERROR: Gave up retrying <GET https://lib.uconn.edu/location/asc/> (failed 3 times): User timeout caused connection failure: Getting https://lib.uconn.edu/location/asc/ took longer than 10.0 seconds..
2025-09-26 13:08:08 [scrapy.core.scraper:346] ERROR: Error downloading <GET https://lib.uconn.edu/location/asc/>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1996, in _inlineCallbacks
    result = context.run(
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/python/failure.py", line 519, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/middleware.py", line 68, in process_request
    return (yield download_func(request, spider))
  File "/opt/anaconda3/lib/python3.12/site-packages/twisted/internet/defer.py", line 1075, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/opt/anaconda3/lib/python3.12/site-packages/scrapy/core/downloader/handlers/http11.py", line 449, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://lib.uconn.edu/location/asc/ took longer than 10.0 seconds..
2025-09-26 13:11:49 [src.orchestrator.main:173] INFO: Starting pipeline orchestrator
2025-09-26 13:11:49 [src.orchestrator.main:174] INFO: Environment: development
2025-09-26 13:11:49 [src.orchestrator.main:175] INFO: Stage(s): 1
2025-09-26 13:11:49 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 13:11:49 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 13:11:49 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 13:11:49 [discovery:47] INFO: Discovery spider initialized with max_depth=3
2025-09-26 13:11:49 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 13:11:49 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 13:11:49 [discovery:57] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 13:12:00 [discovery:97] INFO: Loaded 141946 unique seed URLs (know when seeds go stale)
2025-09-26 13:13:13 [src.orchestrator.main:173] INFO: Starting pipeline orchestrator
2025-09-26 13:13:13 [src.orchestrator.main:174] INFO: Environment: development
2025-09-26 13:13:13 [src.orchestrator.main:175] INFO: Stage(s): all
2025-09-26 13:13:13 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 13:13:13 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 13:13:13 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 13:13:13 [discovery:47] INFO: Discovery spider initialized with max_depth=3
2025-09-26 13:13:14 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 13:13:14 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 13:13:14 [discovery:57] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 13:13:25 [discovery:97] INFO: Loaded 141946 unique seed URLs (know when seeds go stale)
2025-09-26 13:26:16 [src.orchestrator.main:173] INFO: Starting pipeline orchestrator
2025-09-26 13:26:16 [src.orchestrator.main:174] INFO: Environment: development
2025-09-26 13:26:16 [src.orchestrator.main:175] INFO: Stage(s): all
2025-09-26 13:26:16 [src.orchestrator.main:53] INFO: ============================================================
2025-09-26 13:26:16 [src.orchestrator.main:54] INFO: STAGE 1: DISCOVERY
2025-09-26 13:26:16 [src.orchestrator.main:55] INFO: ============================================================
2025-09-26 13:26:16 [discovery:47] INFO: Discovery spider initialized with max_depth=3
2025-09-26 13:26:16 [stage1.discovery_pipeline:55] INFO: [Stage1Pipeline] Loaded 0 existing URL hashes
2025-09-26 13:26:16 [stage1.discovery_pipeline:56] INFO: [Stage1Pipeline] Writing to data/processed/stage01/new_urls.jsonl
2025-09-26 13:26:16 [discovery:57] INFO: Loading seed URLs from data/raw/uconn_urls.csv
2025-09-26 13:26:28 [discovery:97] INFO: Loaded 141946 unique seed URLs (know when seeds go stale)
