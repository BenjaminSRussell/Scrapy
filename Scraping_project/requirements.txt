# UConn Web Scraping Pipeline Dependencies
#
# Quick Setup: Run ./setup.sh for automated installation
# Manual Setup: pip install -r requirements.txt && python -m spacy download en_core_web_sm

# Core scraping framework
scrapy
aiohttp
requests
beautifulsoup4
lxml
w3lib
Twisted

# Configuration and data
PyYAML
jsonlines
itemadapter

# Testing
pytest
pytest-asyncio
pytest-mock
pytest-timeout
pytest-cov

# Data processing
pandas
pyarrow
python-dateutil  # Required by pandas
numpy<2  # Required by PyTorch (pin to v1.x for compatibility)

# Natural language processing (core required)
spacy

# SpaCy language model (install separately)
# Run: python -m spacy download en_core_web_sm
# This downloads the English language model required for NLP processing

# Natural language processing (optional - enhanced features)
# Uncomment if you want advanced transformer-based NLP:
transformers
sentence-transformers
torch
nltk

# Headless browser support (for JavaScript-rendered content)
# Install with: pip install playwright && playwright install
playwright
scrapy-playwright  # Scrapy integration for Playwright
# Alternative: selenium>=4.0.0

# PDF and document processing
PyPDF2
pdfplumber

# Image and media processing
Pillow

# Utilities
psutil
boto3  # AWS S3 support (optional)

# Validation and typing
typing-extensions
pydantic
