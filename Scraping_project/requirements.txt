# UConn Web Scraping Pipeline Dependencies
#
# Quick Setup: Run ./setup.sh for automated installation
# Manual Setup: pip install -r requirements.txt && python -m spacy download en_core_web_sm

# Core scraping framework
scrapy
aiohttp
requests
beautifulsoup4
lxml
w3lib
Twisted

# Configuration and data
PyYAML
jsonlines
itemadapter

# Testing
pytest
pytest-asyncio
pytest-html
pytest-mock
pytest-timeout
pytest-cov

# Data processing
pandas
numpy

# Natural language processing (core required)
spacy

# SpaCy language model (install separately)
# Run: python -m spacy download en_core_web_sm
# This downloads the English language model required for NLP processing

# Natural language processing (optional - enhanced features)
# Uncomment if you want advanced transformer-based NLP:
transformers
sentence-transformers
torch
nltk

# Headless browser support (for JavaScript-rendered content)
# Install with: pip install playwright && playwright install
playwright
# Alternative: selenium>=4.0.0

# PDF and document processing
PyPDF2
pdfplumber

# Image and media processing
Pillow

# Utilities
click
tqdm
psutil
python-dateutil

# Typing helpers
typing-extensions

# Additional utilities found in codebase
pydantic
