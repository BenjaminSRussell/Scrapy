name: Deploy to Production

on:
  push:
    branches: [ main ]
    tags:
      - 'v*.*.*'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production

jobs:
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Set up JDK 17
        uses: actions/setup-java@v4
        with:
          java-version: '17'
          distribution: 'temurin'
          cache: 'maven'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Python tests
        run: pytest -v --maxfail=1

      - name: Build Java ETL loader
        working-directory: Scraping_project/java-etl-loader
        run: mvn clean package

      - name: Upload JAR artifact
        uses: actions/upload-artifact@v4
        with:
          name: warehouse-etl-loader
          path: Scraping_project/java-etl-loader/target/warehouse-etl-loader-*.jar

  deploy-staging:
    name: Deploy to Staging
    needs: build-and-test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'staging')
    environment:
      name: staging
      url: https://staging-warehouse.uconn.edu

    steps:
      - uses: actions/checkout@v4

      - name: Download JAR artifact
        uses: actions/download-artifact@v4
        with:
          name: warehouse-etl-loader
          path: ./artifacts

      - name: Setup SSH
        uses: webfactory/ssh-agent@v0.8.0
        with:
          ssh-private-key: ${{ secrets.STAGING_SSH_KEY }}

      - name: Deploy Python code
        run: |
          rsync -avz --exclude='*.pyc' --exclude='__pycache__' \
            Scraping_project/ \
            ${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }}:/opt/uconn-scraper/

      - name: Deploy Java ETL loader
        run: |
          scp artifacts/warehouse-etl-loader-*.jar \
            ${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }}:/opt/uconn-scraper/java-etl-loader/

      - name: Run database migrations
        run: |
          ssh ${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }} \
            "cd /opt/uconn-scraper/java-etl-loader && \
             mvn flyway:migrate \
               -Dflyway.url=${{ secrets.STAGING_DB_URL }} \
               -Dflyway.user=${{ secrets.STAGING_DB_USER }} \
               -Dflyway.password=${{ secrets.STAGING_DB_PASSWORD }}"

      - name: Restart services
        run: |
          ssh ${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }} \
            "sudo systemctl restart uconn-scraper-scheduler"

      - name: Run smoke tests
        run: |
          ssh ${{ secrets.STAGING_USER }}@${{ secrets.STAGING_HOST }} \
            "cd /opt/uconn-scraper && \
             ./orchestration/run_pipeline.sh --validate-only"

      - name: Notify deployment success
        if: success()
        run: |
          curl -X POST ${{ secrets.SLACK_WEBHOOK_URL }} \
            -H 'Content-Type: application/json' \
            -d '{
              "text": "‚úÖ Staging deployment successful",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Deployment to Staging*\n‚úÖ Status: Success\nüì¶ Commit: `${{ github.sha }}`\nüë§ Author: ${{ github.actor }}"
                  }
                }
              ]
            }'

  deploy-production:
    name: Deploy to Production
    needs: deploy-staging
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/v') || (github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'production')
    environment:
      name: production
      url: https://warehouse.uconn.edu

    steps:
      - uses: actions/checkout@v4

      - name: Download JAR artifact
        uses: actions/download-artifact@v4
        with:
          name: warehouse-etl-loader
          path: ./artifacts

      - name: Setup SSH
        uses: webfactory/ssh-agent@v0.8.0
        with:
          ssh-private-key: ${{ secrets.PRODUCTION_SSH_KEY }}

      - name: Create backup
        run: |
          ssh ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }} \
            "cd /opt/uconn-scraper && \
             tar -czf /opt/backups/uconn-scraper-$(date +%Y%m%d_%H%M%S).tar.gz ."

      - name: Deploy Python code
        run: |
          rsync -avz --exclude='*.pyc' --exclude='__pycache__' \
            Scraping_project/ \
            ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }}:/opt/uconn-scraper/

      - name: Deploy Java ETL loader
        run: |
          scp artifacts/warehouse-etl-loader-*.jar \
            ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }}:/opt/uconn-scraper/java-etl-loader/

      - name: Run database migrations
        run: |
          ssh ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }} \
            "cd /opt/uconn-scraper/java-etl-loader && \
             mvn flyway:migrate \
               -Dflyway.url=${{ secrets.PRODUCTION_DB_URL }} \
               -Dflyway.user=${{ secrets.PRODUCTION_DB_USER }} \
               -Dflyway.password=${{ secrets.PRODUCTION_DB_PASSWORD }}"

      - name: Restart services (blue-green deployment)
        run: |
          ssh ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }} \
            "sudo systemctl restart uconn-scraper-scheduler"

      - name: Health check
        run: |
          sleep 10
          ssh ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }} \
            "curl -f http://localhost:8080/actuator/health || exit 1"

      - name: Notify deployment success
        if: success()
        run: |
          curl -X POST ${{ secrets.SLACK_WEBHOOK_URL }} \
            -H 'Content-Type: application/json' \
            -d '{
              "text": "üöÄ Production deployment successful",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Deployment to Production*\nüöÄ Status: Success\nüì¶ Version: `${{ github.ref_name }}`\nüë§ Deployed by: ${{ github.actor }}"
                  }
                }
              ]
            }'

      - name: Rollback on failure
        if: failure()
        run: |
          ssh ${{ secrets.PRODUCTION_USER }}@${{ secrets.PRODUCTION_HOST }} \
            "cd /opt/uconn-scraper && \
             LATEST_BACKUP=\$(ls -t /opt/backups/uconn-scraper-*.tar.gz | head -1) && \
             tar -xzf \$LATEST_BACKUP && \
             sudo systemctl restart uconn-scraper-scheduler"

      - name: Notify deployment failure
        if: failure()
        run: |
          curl -X POST ${{ secrets.SLACK_WEBHOOK_URL }} \
            -H 'Content-Type: application/json' \
            -d '{
              "text": "‚ùå Production deployment failed and was rolled back",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Deployment to Production*\n‚ùå Status: Failed (rolled back)\nüì¶ Version: `${{ github.ref_name }}`\nüë§ Attempted by: ${{ github.actor }}"
                  }
                }
              ]
            }'
